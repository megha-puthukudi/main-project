{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "16xkdnc8bHeLqMIPCor6DfAEj_fXSugC4",
      "authorship_tag": "ABX9TyOSeRLEpP4NWUV9jfScX7wZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megha-puthukudi/main-project/blob/vgg16_spot/spot_postion_10epochs_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icmpYEFwHTg6",
        "outputId": "3ab48afd-0943-42be-baff-ec82dc1f40bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1050 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n",
            "Epoch 1/30\n",
            "65/65 [==============================] - 21s 291ms/step - loss: 3.8791 - accuracy: 0.3404 - val_loss: 4.1226 - val_accuracy: 0.3527\n",
            "Epoch 2/30\n",
            "65/65 [==============================] - 19s 298ms/step - loss: 3.0399 - accuracy: 0.3859 - val_loss: 3.7279 - val_accuracy: 0.3795\n",
            "Epoch 3/30\n",
            "65/65 [==============================] - 19s 295ms/step - loss: 2.6913 - accuracy: 0.4284 - val_loss: 3.3826 - val_accuracy: 0.3795\n",
            "Epoch 4/30\n",
            "65/65 [==============================] - 21s 318ms/step - loss: 2.4101 - accuracy: 0.4275 - val_loss: 3.0948 - val_accuracy: 0.3973\n",
            "Epoch 5/30\n",
            "65/65 [==============================] - 20s 314ms/step - loss: 2.0934 - accuracy: 0.4952 - val_loss: 2.8399 - val_accuracy: 0.4241\n",
            "Epoch 6/30\n",
            "65/65 [==============================] - 19s 299ms/step - loss: 1.9587 - accuracy: 0.5019 - val_loss: 2.6431 - val_accuracy: 0.4464\n",
            "Epoch 7/30\n",
            "65/65 [==============================] - 19s 290ms/step - loss: 1.8071 - accuracy: 0.5193 - val_loss: 2.5484 - val_accuracy: 0.4509\n",
            "Epoch 8/30\n",
            "65/65 [==============================] - 19s 300ms/step - loss: 1.6651 - accuracy: 0.5609 - val_loss: 2.3559 - val_accuracy: 0.4777\n",
            "Epoch 9/30\n",
            "65/65 [==============================] - 20s 308ms/step - loss: 1.6005 - accuracy: 0.5716 - val_loss: 2.3287 - val_accuracy: 0.4821\n",
            "Epoch 10/30\n",
            "65/65 [==============================] - 20s 311ms/step - loss: 1.5546 - accuracy: 0.5629 - val_loss: 2.1144 - val_accuracy: 0.5089\n",
            "Epoch 11/30\n",
            "65/65 [==============================] - 19s 289ms/step - loss: 1.3742 - accuracy: 0.6238 - val_loss: 2.0334 - val_accuracy: 0.5134\n",
            "Epoch 12/30\n",
            "65/65 [==============================] - 20s 301ms/step - loss: 1.4344 - accuracy: 0.6054 - val_loss: 1.9776 - val_accuracy: 0.5179\n",
            "Epoch 13/30\n",
            "65/65 [==============================] - 19s 286ms/step - loss: 1.3710 - accuracy: 0.6103 - val_loss: 1.9909 - val_accuracy: 0.5045\n",
            "Epoch 14/30\n",
            "65/65 [==============================] - 20s 306ms/step - loss: 1.3413 - accuracy: 0.6122 - val_loss: 1.8464 - val_accuracy: 0.5357\n",
            "Epoch 15/30\n",
            "65/65 [==============================] - 20s 305ms/step - loss: 1.2659 - accuracy: 0.6364 - val_loss: 1.8524 - val_accuracy: 0.5536\n",
            "Epoch 16/30\n",
            "65/65 [==============================] - 20s 301ms/step - loss: 1.2682 - accuracy: 0.6480 - val_loss: 1.8105 - val_accuracy: 0.5536\n",
            "Epoch 17/30\n",
            "65/65 [==============================] - 19s 285ms/step - loss: 1.1257 - accuracy: 0.6586 - val_loss: 1.7690 - val_accuracy: 0.5536\n",
            "Epoch 18/30\n",
            "65/65 [==============================] - 20s 304ms/step - loss: 1.1179 - accuracy: 0.6586 - val_loss: 1.7611 - val_accuracy: 0.5536\n",
            "Epoch 19/30\n",
            "65/65 [==============================] - 19s 289ms/step - loss: 1.1672 - accuracy: 0.6605 - val_loss: 1.7437 - val_accuracy: 0.5491\n",
            "Epoch 20/30\n",
            "65/65 [==============================] - 20s 304ms/step - loss: 1.1289 - accuracy: 0.6731 - val_loss: 1.6640 - val_accuracy: 0.5714\n",
            "Epoch 21/30\n",
            "18/65 [=======>......................] - ETA: 11s - loss: 0.9912 - accuracy: 0.7092"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix\n",
        "import seaborn as sns  # Added seaborn for visualization\n",
        "\n",
        "# Define your data directories\n",
        "train_dir = '/content/drive/MyDrive/dataset for spot/train'\n",
        "val_dir = '/content/drive/MyDrive/dataset for spot/validation'\n",
        "test_dir = '/content/drive/MyDrive/dataset for spot/test'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add a global average pooling layer and a dense layer for classification\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "predictions = Dense(3, activation='softmax')(x)  # Assuming 2 classes\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.n // batch_size)\n",
        "train_loss, train_accuracy = model.evaluate(train_generator, steps=train_generator.n // batch_size)\n",
        "\n",
        "# Calculate recall\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i in range(test_generator.n // batch_size):\n",
        "    batch_x, batch_y = next(test_generator)\n",
        "    y_true.extend(np.argmax(batch_y, axis=1))\n",
        "    y_pred.extend(np.argmax(model.predict(batch_x), axis=1))\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['front', 'rear', 'side'], yticklabels=['front', 'rear', 'side'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Calculate other metrics\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "# Display metrics\n",
        "print(f'Test loss: {test_loss:.4f}')\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}')\n",
        "print(f'Train loss: {train_loss:.4f}')\n",
        "print(f'Train accuracy: {train_accuracy * 100:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/colabtest/vecicle_spot_position_VGG16_epoch_30_dataset.h5')\n"
      ]
    }
  ]
}