{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "14Mrw-oDPeVTvMgZ5fr5KJu4_A_g81jxd",
      "authorship_tag": "ABX9TyOhOfFfk2a4nkt2ND6gNTxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megha-puthukudi/main-project/blob/VGG16-SEVERE/vecicle_damage_VGG16_epoch_60_severity_new_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rh35Pk_6UfeZ",
        "outputId": "8809e51c-4289-4c7a-c140-fc676ffcb968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1150 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n",
            "Epoch 1/200\n",
            "71/71 [==============================] - 37s 512ms/step - loss: 1.0066 - accuracy: 0.4832 - val_loss: 0.8958 - val_accuracy: 0.5491\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 23s 316ms/step - loss: 0.8938 - accuracy: 0.5750 - val_loss: 0.8971 - val_accuracy: 0.5134\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.8436 - accuracy: 0.5829 - val_loss: 0.8642 - val_accuracy: 0.5938\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.7914 - accuracy: 0.6226 - val_loss: 0.8299 - val_accuracy: 0.5982\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.7782 - accuracy: 0.6420 - val_loss: 0.8112 - val_accuracy: 0.6116\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 23s 321ms/step - loss: 0.7716 - accuracy: 0.6446 - val_loss: 0.8179 - val_accuracy: 0.5670\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 23s 331ms/step - loss: 0.7535 - accuracy: 0.6490 - val_loss: 0.8426 - val_accuracy: 0.6027\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.7352 - accuracy: 0.6526 - val_loss: 0.8138 - val_accuracy: 0.5982\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.7291 - accuracy: 0.6587 - val_loss: 0.8569 - val_accuracy: 0.5982\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 22s 312ms/step - loss: 0.7090 - accuracy: 0.6772 - val_loss: 0.8138 - val_accuracy: 0.5804\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.7026 - accuracy: 0.7002 - val_loss: 0.8292 - val_accuracy: 0.6116\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 22s 306ms/step - loss: 0.6924 - accuracy: 0.6817 - val_loss: 0.8305 - val_accuracy: 0.6071\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.6934 - accuracy: 0.6808 - val_loss: 0.8405 - val_accuracy: 0.6205\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.7013 - accuracy: 0.6808 - val_loss: 0.8399 - val_accuracy: 0.5982\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.6887 - accuracy: 0.6887 - val_loss: 0.8391 - val_accuracy: 0.5982\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.6680 - accuracy: 0.7240 - val_loss: 0.8264 - val_accuracy: 0.6250\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.6753 - accuracy: 0.7028 - val_loss: 0.8402 - val_accuracy: 0.5714\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 24s 332ms/step - loss: 0.6785 - accuracy: 0.6984 - val_loss: 0.8300 - val_accuracy: 0.6071\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.6569 - accuracy: 0.7148 - val_loss: 0.8273 - val_accuracy: 0.6071\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 22s 313ms/step - loss: 0.6599 - accuracy: 0.6975 - val_loss: 0.8962 - val_accuracy: 0.6116\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 23s 321ms/step - loss: 0.6599 - accuracy: 0.7134 - val_loss: 0.8630 - val_accuracy: 0.6071\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.6544 - accuracy: 0.7090 - val_loss: 0.9101 - val_accuracy: 0.5804\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 22s 312ms/step - loss: 0.6421 - accuracy: 0.7187 - val_loss: 0.8560 - val_accuracy: 0.5759\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.6507 - accuracy: 0.7081 - val_loss: 0.8526 - val_accuracy: 0.5893\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 22s 312ms/step - loss: 0.6418 - accuracy: 0.7205 - val_loss: 0.9082 - val_accuracy: 0.6161\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.6369 - accuracy: 0.7319 - val_loss: 0.8512 - val_accuracy: 0.6071\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.6431 - accuracy: 0.7143 - val_loss: 0.8601 - val_accuracy: 0.6250\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.6295 - accuracy: 0.7257 - val_loss: 0.9187 - val_accuracy: 0.6071\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.6056 - accuracy: 0.7425 - val_loss: 0.8722 - val_accuracy: 0.6384\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.6153 - accuracy: 0.7478 - val_loss: 0.8606 - val_accuracy: 0.6250\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.5982 - accuracy: 0.7513 - val_loss: 0.9045 - val_accuracy: 0.6295\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.6066 - accuracy: 0.7460 - val_loss: 0.9097 - val_accuracy: 0.6205\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.6040 - accuracy: 0.7430 - val_loss: 0.8651 - val_accuracy: 0.6071\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.5970 - accuracy: 0.7403 - val_loss: 0.9344 - val_accuracy: 0.5893\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.6030 - accuracy: 0.7381 - val_loss: 0.8813 - val_accuracy: 0.6205\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 24s 332ms/step - loss: 0.5923 - accuracy: 0.7319 - val_loss: 0.8749 - val_accuracy: 0.6161\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 22s 307ms/step - loss: 0.6188 - accuracy: 0.7266 - val_loss: 0.9010 - val_accuracy: 0.6027\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.5738 - accuracy: 0.7593 - val_loss: 0.8769 - val_accuracy: 0.6384\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.5936 - accuracy: 0.7434 - val_loss: 0.8737 - val_accuracy: 0.6161\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 22s 306ms/step - loss: 0.6056 - accuracy: 0.7460 - val_loss: 0.9194 - val_accuracy: 0.6429\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.5873 - accuracy: 0.7504 - val_loss: 0.9249 - val_accuracy: 0.6205\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.5809 - accuracy: 0.7549 - val_loss: 0.8864 - val_accuracy: 0.6384\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.5987 - accuracy: 0.7434 - val_loss: 0.8781 - val_accuracy: 0.6161\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 22s 304ms/step - loss: 0.5777 - accuracy: 0.7637 - val_loss: 0.8769 - val_accuracy: 0.6339\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.5662 - accuracy: 0.7672 - val_loss: 0.8794 - val_accuracy: 0.6116\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.5777 - accuracy: 0.7478 - val_loss: 0.8755 - val_accuracy: 0.6473\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.5594 - accuracy: 0.7610 - val_loss: 0.9179 - val_accuracy: 0.6116\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.5902 - accuracy: 0.7557 - val_loss: 0.8934 - val_accuracy: 0.6339\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.5476 - accuracy: 0.7628 - val_loss: 0.8756 - val_accuracy: 0.6205\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.5375 - accuracy: 0.7601 - val_loss: 0.9060 - val_accuracy: 0.6473\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.5737 - accuracy: 0.7549 - val_loss: 0.8885 - val_accuracy: 0.6384\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 24s 334ms/step - loss: 0.5630 - accuracy: 0.7734 - val_loss: 0.9221 - val_accuracy: 0.6473\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 22s 309ms/step - loss: 0.5440 - accuracy: 0.7764 - val_loss: 0.9947 - val_accuracy: 0.5714\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.5688 - accuracy: 0.7566 - val_loss: 0.8969 - val_accuracy: 0.6205\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 22s 311ms/step - loss: 0.5474 - accuracy: 0.7540 - val_loss: 0.9445 - val_accuracy: 0.6295\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.5616 - accuracy: 0.7540 - val_loss: 0.9314 - val_accuracy: 0.6295\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.5515 - accuracy: 0.7857 - val_loss: 0.9179 - val_accuracy: 0.6250\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 22s 314ms/step - loss: 0.5380 - accuracy: 0.7769 - val_loss: 0.9279 - val_accuracy: 0.6116\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.5260 - accuracy: 0.7866 - val_loss: 0.9883 - val_accuracy: 0.6295\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.5497 - accuracy: 0.7720 - val_loss: 0.9137 - val_accuracy: 0.6429\n",
            "Epoch 61/200\n",
            "71/71 [==============================] - 24s 345ms/step - loss: 0.5416 - accuracy: 0.7646 - val_loss: 0.8994 - val_accuracy: 0.6295\n",
            "Epoch 62/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.5264 - accuracy: 0.7787 - val_loss: 0.9152 - val_accuracy: 0.6562\n",
            "Epoch 63/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.5414 - accuracy: 0.7831 - val_loss: 0.8958 - val_accuracy: 0.6339\n",
            "Epoch 64/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.5341 - accuracy: 0.7822 - val_loss: 0.9203 - val_accuracy: 0.6429\n",
            "Epoch 65/200\n",
            "71/71 [==============================] - 22s 312ms/step - loss: 0.5274 - accuracy: 0.7840 - val_loss: 0.9248 - val_accuracy: 0.6384\n",
            "Epoch 66/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.5106 - accuracy: 0.7848 - val_loss: 0.9269 - val_accuracy: 0.6250\n",
            "Epoch 67/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.5449 - accuracy: 0.7663 - val_loss: 0.9565 - val_accuracy: 0.6116\n",
            "Epoch 68/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.5237 - accuracy: 0.7884 - val_loss: 0.9160 - val_accuracy: 0.6339\n",
            "Epoch 69/200\n",
            "71/71 [==============================] - 22s 316ms/step - loss: 0.5261 - accuracy: 0.7910 - val_loss: 0.9400 - val_accuracy: 0.6161\n",
            "Epoch 70/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.5269 - accuracy: 0.7919 - val_loss: 0.9467 - val_accuracy: 0.5893\n",
            "Epoch 71/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.5184 - accuracy: 0.7945 - val_loss: 0.9230 - val_accuracy: 0.6473\n",
            "Epoch 72/200\n",
            "71/71 [==============================] - 24s 329ms/step - loss: 0.5219 - accuracy: 0.7804 - val_loss: 0.9312 - val_accuracy: 0.6250\n",
            "Epoch 73/200\n",
            "71/71 [==============================] - 22s 313ms/step - loss: 0.5145 - accuracy: 0.7892 - val_loss: 0.9405 - val_accuracy: 0.6250\n",
            "Epoch 74/200\n",
            "71/71 [==============================] - 24s 335ms/step - loss: 0.5133 - accuracy: 0.7928 - val_loss: 0.9356 - val_accuracy: 0.6250\n",
            "Epoch 75/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.5262 - accuracy: 0.7804 - val_loss: 0.9372 - val_accuracy: 0.6295\n",
            "Epoch 76/200\n",
            "71/71 [==============================] - 24s 335ms/step - loss: 0.5166 - accuracy: 0.7840 - val_loss: 0.9472 - val_accuracy: 0.6295\n",
            "Epoch 77/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.5158 - accuracy: 0.7866 - val_loss: 0.9282 - val_accuracy: 0.6250\n",
            "Epoch 78/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.5101 - accuracy: 0.7972 - val_loss: 0.9369 - val_accuracy: 0.6205\n",
            "Epoch 79/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.5013 - accuracy: 0.7989 - val_loss: 0.9786 - val_accuracy: 0.6384\n",
            "Epoch 80/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.5202 - accuracy: 0.7822 - val_loss: 0.9326 - val_accuracy: 0.6250\n",
            "Epoch 81/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.5031 - accuracy: 0.7919 - val_loss: 0.9525 - val_accuracy: 0.6071\n",
            "Epoch 82/200\n",
            "71/71 [==============================] - 24s 332ms/step - loss: 0.5091 - accuracy: 0.7848 - val_loss: 0.9516 - val_accuracy: 0.6161\n",
            "Epoch 83/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4934 - accuracy: 0.7937 - val_loss: 1.0026 - val_accuracy: 0.6027\n",
            "Epoch 84/200\n",
            "71/71 [==============================] - 22s 309ms/step - loss: 0.5174 - accuracy: 0.7901 - val_loss: 0.9746 - val_accuracy: 0.6116\n",
            "Epoch 85/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.5299 - accuracy: 0.7848 - val_loss: 1.0226 - val_accuracy: 0.6161\n",
            "Epoch 86/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.5016 - accuracy: 0.7919 - val_loss: 0.9264 - val_accuracy: 0.6205\n",
            "Epoch 87/200\n",
            "71/71 [==============================] - 22s 307ms/step - loss: 0.5190 - accuracy: 0.7787 - val_loss: 0.9451 - val_accuracy: 0.6295\n",
            "Epoch 88/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.4903 - accuracy: 0.8069 - val_loss: 1.0040 - val_accuracy: 0.6205\n",
            "Epoch 89/200\n",
            "71/71 [==============================] - 22s 306ms/step - loss: 0.4950 - accuracy: 0.7892 - val_loss: 0.9764 - val_accuracy: 0.6071\n",
            "Epoch 90/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.5174 - accuracy: 0.7892 - val_loss: 1.0005 - val_accuracy: 0.6116\n",
            "Epoch 91/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.5053 - accuracy: 0.7945 - val_loss: 0.9777 - val_accuracy: 0.6116\n",
            "Epoch 92/200\n",
            "71/71 [==============================] - 24s 333ms/step - loss: 0.4849 - accuracy: 0.8078 - val_loss: 0.9731 - val_accuracy: 0.6205\n",
            "Epoch 93/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.4903 - accuracy: 0.8025 - val_loss: 1.0476 - val_accuracy: 0.6205\n",
            "Epoch 94/200\n",
            "71/71 [==============================] - 24s 334ms/step - loss: 0.4807 - accuracy: 0.8166 - val_loss: 0.9859 - val_accuracy: 0.6161\n",
            "Epoch 95/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4855 - accuracy: 0.8069 - val_loss: 0.9721 - val_accuracy: 0.6250\n",
            "Epoch 96/200\n",
            "71/71 [==============================] - 23s 321ms/step - loss: 0.5193 - accuracy: 0.7848 - val_loss: 0.9775 - val_accuracy: 0.6295\n",
            "Epoch 97/200\n",
            "71/71 [==============================] - 22s 311ms/step - loss: 0.5094 - accuracy: 0.7840 - val_loss: 1.0170 - val_accuracy: 0.5982\n",
            "Epoch 98/200\n",
            "71/71 [==============================] - 24s 344ms/step - loss: 0.5245 - accuracy: 0.7769 - val_loss: 0.9961 - val_accuracy: 0.6250\n",
            "Epoch 99/200\n",
            "71/71 [==============================] - 22s 311ms/step - loss: 0.4936 - accuracy: 0.7989 - val_loss: 0.9789 - val_accuracy: 0.6339\n",
            "Epoch 100/200\n",
            "71/71 [==============================] - 24s 331ms/step - loss: 0.5037 - accuracy: 0.8051 - val_loss: 1.0168 - val_accuracy: 0.6071\n",
            "Epoch 101/200\n",
            "71/71 [==============================] - 22s 311ms/step - loss: 0.4725 - accuracy: 0.8007 - val_loss: 1.0037 - val_accuracy: 0.6027\n",
            "Epoch 102/200\n",
            "71/71 [==============================] - 24s 334ms/step - loss: 0.4581 - accuracy: 0.8139 - val_loss: 0.9790 - val_accuracy: 0.6339\n",
            "Epoch 103/200\n",
            "71/71 [==============================] - 24s 332ms/step - loss: 0.4980 - accuracy: 0.7840 - val_loss: 0.9535 - val_accuracy: 0.6384\n",
            "Epoch 104/200\n",
            "71/71 [==============================] - 22s 315ms/step - loss: 0.4680 - accuracy: 0.8069 - val_loss: 0.9642 - val_accuracy: 0.6250\n",
            "Epoch 105/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.4705 - accuracy: 0.8104 - val_loss: 0.9590 - val_accuracy: 0.6339\n",
            "Epoch 106/200\n",
            "71/71 [==============================] - 23s 317ms/step - loss: 0.4817 - accuracy: 0.8131 - val_loss: 0.9821 - val_accuracy: 0.6295\n",
            "Epoch 107/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.4971 - accuracy: 0.7981 - val_loss: 0.9941 - val_accuracy: 0.6250\n",
            "Epoch 108/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.4698 - accuracy: 0.8025 - val_loss: 0.9999 - val_accuracy: 0.6339\n",
            "Epoch 109/200\n",
            "71/71 [==============================] - 24s 340ms/step - loss: 0.4776 - accuracy: 0.8016 - val_loss: 1.0661 - val_accuracy: 0.6116\n",
            "Epoch 110/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.4880 - accuracy: 0.7919 - val_loss: 1.0141 - val_accuracy: 0.6161\n",
            "Epoch 111/200\n",
            "71/71 [==============================] - 22s 311ms/step - loss: 0.4922 - accuracy: 0.8034 - val_loss: 1.0243 - val_accuracy: 0.6116\n",
            "Epoch 112/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.4707 - accuracy: 0.8016 - val_loss: 1.0356 - val_accuracy: 0.6250\n",
            "Epoch 113/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4863 - accuracy: 0.8025 - val_loss: 1.0221 - val_accuracy: 0.6295\n",
            "Epoch 114/200\n",
            "71/71 [==============================] - 24s 332ms/step - loss: 0.4861 - accuracy: 0.7989 - val_loss: 1.0115 - val_accuracy: 0.6205\n",
            "Epoch 115/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.4609 - accuracy: 0.8104 - val_loss: 1.0230 - val_accuracy: 0.6161\n",
            "Epoch 116/200\n",
            "71/71 [==============================] - 23s 319ms/step - loss: 0.4420 - accuracy: 0.8245 - val_loss: 1.0051 - val_accuracy: 0.6339\n",
            "Epoch 117/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.4877 - accuracy: 0.8148 - val_loss: 1.0052 - val_accuracy: 0.6205\n",
            "Epoch 118/200\n",
            "71/71 [==============================] - 24s 332ms/step - loss: 0.4753 - accuracy: 0.8060 - val_loss: 1.0236 - val_accuracy: 0.6295\n",
            "Epoch 119/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.4674 - accuracy: 0.8095 - val_loss: 1.0257 - val_accuracy: 0.6205\n",
            "Epoch 120/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.4792 - accuracy: 0.8086 - val_loss: 0.9915 - val_accuracy: 0.6339\n",
            "Epoch 121/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4628 - accuracy: 0.8025 - val_loss: 0.9822 - val_accuracy: 0.6429\n",
            "Epoch 122/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.4518 - accuracy: 0.8113 - val_loss: 1.0248 - val_accuracy: 0.6339\n",
            "Epoch 123/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.4694 - accuracy: 0.8139 - val_loss: 0.9820 - val_accuracy: 0.6384\n",
            "Epoch 124/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.4623 - accuracy: 0.8104 - val_loss: 1.0093 - val_accuracy: 0.6339\n",
            "Epoch 125/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.4798 - accuracy: 0.7998 - val_loss: 1.0019 - val_accuracy: 0.6429\n",
            "Epoch 126/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4717 - accuracy: 0.8086 - val_loss: 0.9675 - val_accuracy: 0.6429\n",
            "Epoch 127/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4432 - accuracy: 0.8263 - val_loss: 1.0147 - val_accuracy: 0.6295\n",
            "Epoch 128/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.4476 - accuracy: 0.8228 - val_loss: 1.0167 - val_accuracy: 0.6339\n",
            "Epoch 129/200\n",
            "71/71 [==============================] - 22s 315ms/step - loss: 0.4758 - accuracy: 0.7981 - val_loss: 0.9984 - val_accuracy: 0.6384\n",
            "Epoch 130/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4649 - accuracy: 0.8104 - val_loss: 0.9970 - val_accuracy: 0.6250\n",
            "Epoch 131/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.4527 - accuracy: 0.8245 - val_loss: 1.0069 - val_accuracy: 0.6071\n",
            "Epoch 132/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.4676 - accuracy: 0.8175 - val_loss: 1.0381 - val_accuracy: 0.5848\n",
            "Epoch 133/200\n",
            "71/71 [==============================] - 24s 331ms/step - loss: 0.4607 - accuracy: 0.8210 - val_loss: 1.0038 - val_accuracy: 0.6295\n",
            "Epoch 134/200\n",
            "71/71 [==============================] - 23s 331ms/step - loss: 0.4643 - accuracy: 0.8113 - val_loss: 0.9879 - val_accuracy: 0.6339\n",
            "Epoch 135/200\n",
            "71/71 [==============================] - 24s 333ms/step - loss: 0.4682 - accuracy: 0.8122 - val_loss: 1.0412 - val_accuracy: 0.6250\n",
            "Epoch 136/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4448 - accuracy: 0.8254 - val_loss: 0.9997 - val_accuracy: 0.6473\n",
            "Epoch 137/200\n",
            "71/71 [==============================] - 24s 333ms/step - loss: 0.4488 - accuracy: 0.8069 - val_loss: 0.9964 - val_accuracy: 0.6295\n",
            "Epoch 138/200\n",
            "71/71 [==============================] - 22s 315ms/step - loss: 0.4654 - accuracy: 0.8175 - val_loss: 1.0105 - val_accuracy: 0.6384\n",
            "Epoch 139/200\n",
            "71/71 [==============================] - 24s 333ms/step - loss: 0.4572 - accuracy: 0.8104 - val_loss: 1.0317 - val_accuracy: 0.6161\n",
            "Epoch 140/200\n",
            "71/71 [==============================] - 22s 314ms/step - loss: 0.4624 - accuracy: 0.8078 - val_loss: 0.9976 - val_accuracy: 0.6295\n",
            "Epoch 141/200\n",
            "71/71 [==============================] - 23s 328ms/step - loss: 0.4422 - accuracy: 0.8280 - val_loss: 1.0481 - val_accuracy: 0.6116\n",
            "Epoch 142/200\n",
            "71/71 [==============================] - 25s 346ms/step - loss: 0.4886 - accuracy: 0.7981 - val_loss: 1.0564 - val_accuracy: 0.6473\n",
            "Epoch 143/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4449 - accuracy: 0.8183 - val_loss: 1.0361 - val_accuracy: 0.6339\n",
            "Epoch 144/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4750 - accuracy: 0.7945 - val_loss: 1.0827 - val_accuracy: 0.6250\n",
            "Epoch 145/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.4465 - accuracy: 0.8201 - val_loss: 1.0023 - val_accuracy: 0.6339\n",
            "Epoch 146/200\n",
            "71/71 [==============================] - 22s 315ms/step - loss: 0.4402 - accuracy: 0.8201 - val_loss: 1.0582 - val_accuracy: 0.6295\n",
            "Epoch 147/200\n",
            "71/71 [==============================] - 23s 329ms/step - loss: 0.4520 - accuracy: 0.8175 - val_loss: 1.0280 - val_accuracy: 0.6339\n",
            "Epoch 148/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.4550 - accuracy: 0.8007 - val_loss: 1.0356 - val_accuracy: 0.6205\n",
            "Epoch 149/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4519 - accuracy: 0.8307 - val_loss: 1.0737 - val_accuracy: 0.6071\n",
            "Epoch 150/200\n",
            "71/71 [==============================] - 24s 341ms/step - loss: 0.4365 - accuracy: 0.8245 - val_loss: 1.0473 - val_accuracy: 0.6295\n",
            "Epoch 151/200\n",
            "71/71 [==============================] - 24s 337ms/step - loss: 0.4427 - accuracy: 0.8210 - val_loss: 0.9871 - val_accuracy: 0.6473\n",
            "Epoch 152/200\n",
            "71/71 [==============================] - 22s 314ms/step - loss: 0.4246 - accuracy: 0.8439 - val_loss: 1.0061 - val_accuracy: 0.6607\n",
            "Epoch 153/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.4227 - accuracy: 0.8360 - val_loss: 1.0781 - val_accuracy: 0.6250\n",
            "Epoch 154/200\n",
            "71/71 [==============================] - 23s 330ms/step - loss: 0.4418 - accuracy: 0.8351 - val_loss: 1.0616 - val_accuracy: 0.6205\n",
            "Epoch 155/200\n",
            "71/71 [==============================] - 24s 335ms/step - loss: 0.4382 - accuracy: 0.8280 - val_loss: 1.0209 - val_accuracy: 0.6429\n",
            "Epoch 156/200\n",
            "71/71 [==============================] - 22s 307ms/step - loss: 0.4578 - accuracy: 0.8245 - val_loss: 1.0490 - val_accuracy: 0.6205\n",
            "Epoch 157/200\n",
            "71/71 [==============================] - 23s 320ms/step - loss: 0.4401 - accuracy: 0.8228 - val_loss: 1.1006 - val_accuracy: 0.6384\n",
            "Epoch 158/200\n",
            "71/71 [==============================] - 22s 309ms/step - loss: 0.4221 - accuracy: 0.8280 - val_loss: 1.0143 - val_accuracy: 0.6295\n",
            "Epoch 159/200\n",
            "71/71 [==============================] - 24s 331ms/step - loss: 0.4384 - accuracy: 0.8201 - val_loss: 1.0590 - val_accuracy: 0.6161\n",
            "Epoch 160/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4608 - accuracy: 0.8228 - val_loss: 1.0779 - val_accuracy: 0.6250\n",
            "Epoch 161/200\n",
            "71/71 [==============================] - 22s 306ms/step - loss: 0.4538 - accuracy: 0.8175 - val_loss: 1.0044 - val_accuracy: 0.6473\n",
            "Epoch 162/200\n",
            "71/71 [==============================] - 24s 331ms/step - loss: 0.4436 - accuracy: 0.8192 - val_loss: 1.0047 - val_accuracy: 0.6429\n",
            "Epoch 163/200\n",
            "71/71 [==============================] - 22s 312ms/step - loss: 0.4391 - accuracy: 0.8210 - val_loss: 1.0055 - val_accuracy: 0.6518\n",
            "Epoch 164/200\n",
            "71/71 [==============================] - 23s 317ms/step - loss: 0.4619 - accuracy: 0.8166 - val_loss: 1.0445 - val_accuracy: 0.6205\n",
            "Epoch 165/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4277 - accuracy: 0.8404 - val_loss: 1.0242 - val_accuracy: 0.6161\n",
            "Epoch 166/200\n",
            "71/71 [==============================] - 22s 303ms/step - loss: 0.4184 - accuracy: 0.8289 - val_loss: 1.0313 - val_accuracy: 0.6429\n",
            "Epoch 167/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4551 - accuracy: 0.8219 - val_loss: 1.0441 - val_accuracy: 0.6250\n",
            "Epoch 168/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4462 - accuracy: 0.8139 - val_loss: 1.0337 - val_accuracy: 0.6384\n",
            "Epoch 169/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.4300 - accuracy: 0.8413 - val_loss: 1.0463 - val_accuracy: 0.6250\n",
            "Epoch 170/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.4411 - accuracy: 0.8245 - val_loss: 1.0667 - val_accuracy: 0.6429\n",
            "Epoch 171/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4116 - accuracy: 0.8386 - val_loss: 1.0794 - val_accuracy: 0.6116\n",
            "Epoch 172/200\n",
            "71/71 [==============================] - 22s 309ms/step - loss: 0.4289 - accuracy: 0.8386 - val_loss: 1.0791 - val_accuracy: 0.6384\n",
            "Epoch 173/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.4339 - accuracy: 0.8236 - val_loss: 1.0382 - val_accuracy: 0.6250\n",
            "Epoch 174/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.4292 - accuracy: 0.8201 - val_loss: 1.0262 - val_accuracy: 0.6250\n",
            "Epoch 175/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.4168 - accuracy: 0.8325 - val_loss: 1.0849 - val_accuracy: 0.6161\n",
            "Epoch 176/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4315 - accuracy: 0.8219 - val_loss: 1.0335 - val_accuracy: 0.6473\n",
            "Epoch 177/200\n",
            "71/71 [==============================] - 23s 322ms/step - loss: 0.4252 - accuracy: 0.8245 - val_loss: 1.0255 - val_accuracy: 0.6384\n",
            "Epoch 178/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4262 - accuracy: 0.8272 - val_loss: 1.0890 - val_accuracy: 0.6339\n",
            "Epoch 179/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.4186 - accuracy: 0.8404 - val_loss: 1.0774 - val_accuracy: 0.6205\n",
            "Epoch 180/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.4427 - accuracy: 0.8236 - val_loss: 1.1564 - val_accuracy: 0.6250\n",
            "Epoch 181/200\n",
            "71/71 [==============================] - 22s 307ms/step - loss: 0.4090 - accuracy: 0.8377 - val_loss: 1.0599 - val_accuracy: 0.6429\n",
            "Epoch 182/200\n",
            "71/71 [==============================] - 24s 338ms/step - loss: 0.4159 - accuracy: 0.8192 - val_loss: 1.0812 - val_accuracy: 0.6429\n",
            "Epoch 183/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4190 - accuracy: 0.8377 - val_loss: 1.0404 - val_accuracy: 0.6295\n",
            "Epoch 184/200\n",
            "71/71 [==============================] - 22s 312ms/step - loss: 0.4179 - accuracy: 0.8245 - val_loss: 1.0925 - val_accuracy: 0.6116\n",
            "Epoch 185/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4413 - accuracy: 0.8245 - val_loss: 1.0459 - val_accuracy: 0.6429\n",
            "Epoch 186/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.4171 - accuracy: 0.8280 - val_loss: 1.0541 - val_accuracy: 0.6339\n",
            "Epoch 187/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.4319 - accuracy: 0.8254 - val_loss: 1.0891 - val_accuracy: 0.6295\n",
            "Epoch 188/200\n",
            "71/71 [==============================] - 23s 327ms/step - loss: 0.4120 - accuracy: 0.8430 - val_loss: 1.0877 - val_accuracy: 0.6339\n",
            "Epoch 189/200\n",
            "71/71 [==============================] - 23s 318ms/step - loss: 0.4080 - accuracy: 0.8369 - val_loss: 1.1005 - val_accuracy: 0.6071\n",
            "Epoch 190/200\n",
            "71/71 [==============================] - 22s 310ms/step - loss: 0.4245 - accuracy: 0.8298 - val_loss: 1.0517 - val_accuracy: 0.6250\n",
            "Epoch 191/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.4084 - accuracy: 0.8439 - val_loss: 1.0974 - val_accuracy: 0.6116\n",
            "Epoch 192/200\n",
            "71/71 [==============================] - 23s 321ms/step - loss: 0.4156 - accuracy: 0.8298 - val_loss: 1.0602 - val_accuracy: 0.6384\n",
            "Epoch 193/200\n",
            "71/71 [==============================] - 23s 325ms/step - loss: 0.4491 - accuracy: 0.8131 - val_loss: 1.0978 - val_accuracy: 0.6205\n",
            "Epoch 194/200\n",
            "71/71 [==============================] - 23s 326ms/step - loss: 0.4113 - accuracy: 0.8333 - val_loss: 1.1266 - val_accuracy: 0.6295\n",
            "Epoch 195/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4165 - accuracy: 0.8386 - val_loss: 1.0724 - val_accuracy: 0.6473\n",
            "Epoch 196/200\n",
            "71/71 [==============================] - 23s 324ms/step - loss: 0.4083 - accuracy: 0.8386 - val_loss: 1.0743 - val_accuracy: 0.6339\n",
            "Epoch 197/200\n",
            "71/71 [==============================] - 23s 315ms/step - loss: 0.4480 - accuracy: 0.8060 - val_loss: 1.0914 - val_accuracy: 0.6071\n",
            "Epoch 198/200\n",
            "71/71 [==============================] - 22s 308ms/step - loss: 0.4340 - accuracy: 0.8219 - val_loss: 1.0676 - val_accuracy: 0.6384\n",
            "Epoch 199/200\n",
            "71/71 [==============================] - 23s 323ms/step - loss: 0.4297 - accuracy: 0.8192 - val_loss: 1.0635 - val_accuracy: 0.6161\n",
            "Epoch 200/200\n",
            "71/71 [==============================] - 22s 305ms/step - loss: 0.4265 - accuracy: 0.8228 - val_loss: 1.0934 - val_accuracy: 0.6250\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 1.1328 - accuracy: 0.6518\n",
            "71/71 [==============================] - 21s 293ms/step - loss: 0.3988 - accuracy: 0.8424\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIjCAYAAACTRapjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXCElEQVR4nO3dd3gU1fv38c8Gkk1ITyAJoYQmTVCqEEFqFAEpBguKEpoFYyPYUJEmRvlKU5oFAypFKaKigvQmKCAIIoYuKiQgECCBFJJ5/uBhf64BzcaEWTPvl9dcF3tm5sw9ca9wc58zZ2yGYRgCAACAZXiYHQAAAACuLhJAAAAAiyEBBAAAsBgSQAAAAIshAQQAALAYEkAAAACLIQEEAACwGBJAAAAAiyEBBAAAsBgSQAB/a+/evbrlllsUGBgom82mRYsWFWn/hw4dks1m04wZM4q03/+yNm3aqE2bNmaHAaAEIwEE/gP279+vhx56SNWqVZO3t7cCAgLUokULTZw4UefPny/Wa8fFxWnnzp0aPXq0PvjgAzVp0qRYr3c19enTRzabTQEBAZf9Oe7du1c2m002m02vv/66y/0fOXJEw4cP1/bt24sgWgAoOqXNDgDA3/viiy905513ym63q3fv3qpXr56ys7O1fv16Pf3009q1a5fefvvtYrn2+fPntXHjRr3wwgt69NFHi+UaUVFROn/+vDw9PYul/39SunRpnTt3Tp9//rnuuusup32zZs2St7e3MjMzC9X3kSNHNGLECFWpUkUNGjQo8Hlff/11oa4HAAVFAgi4sYMHD6pnz56KiorSypUrVb58ece++Ph47du3T1988UWxXf/48eOSpKCgoGK7hs1mk7e3d7H1/0/sdrtatGihOXPm5EsAZ8+erc6dO2vBggVXJZZz586pTJky8vLyuirXA2BdDAEDbmzMmDFKT0/X9OnTnZK/S2rUqKEnnnjC8fnChQsaNWqUqlevLrvdripVquj5559XVlaW03lVqlTRbbfdpvXr1+uGG26Qt7e3qlWrpvfff99xzPDhwxUVFSVJevrpp2Wz2VSlShVJF4dOL/35z4YPHy6bzebUtmzZMrVs2VJBQUHy8/NTrVq19Pzzzzv2X2kO4MqVK3XTTTfJ19dXQUFB6tatm3bv3n3Z6+3bt099+vRRUFCQAgMD1bdvX507d+7KP9i/uPfee/XVV18pLS3N0bZ582bt3btX9957b77jT548qaeeekr169eXn5+fAgIC1LFjR/3www+OY1avXq2mTZtKkvr27esYSr50n23atFG9evW0detWtWrVSmXKlHH8XP46BzAuLk7e3t757r9Dhw4KDg7WkSNHCnyvACCRAAJu7fPPP1e1atV04403Fuj4AQMG6KWXXlKjRo00fvx4tW7dWomJierZs2e+Y/ft26c77rhDN998s8aOHavg4GD16dNHu3btkiTFxsZq/PjxkqR77rlHH3zwgSZMmOBS/Lt27dJtt92mrKwsjRw5UmPHjlXXrl21YcOGvz1v+fLl6tChg44dO6bhw4crISFB33zzjVq0aKFDhw7lO/6uu+7S2bNnlZiYqLvuukszZszQiBEjChxnbGysbDabFi5c6GibPXu2ateurUaNGuU7/sCBA1q0aJFuu+02jRs3Tk8//bR27typ1q1bO5KxOnXqaOTIkZKkBx98UB988IE++OADtWrVytHPiRMn1LFjRzVo0EATJkxQ27ZtLxvfxIkTVa5cOcXFxSk3N1eS9NZbb+nrr7/Wm2++qcjIyALfKwBIkgwAbun06dOGJKNbt24FOn779u2GJGPAgAFO7U899ZQhyVi5cqWjLSoqypBkrF271tF27Ngxw263G4MHD3a0HTx40JBk/O9//3PqMy4uzoiKisoXw7Bhw4w//1oZP368Ick4fvz4FeO+dI2kpCRHW4MGDYywsDDjxIkTjrYffvjB8PDwMHr37p3vev369XPq8/bbbzdCQ0OveM0/34evr69hGIZxxx13GO3btzcMwzByc3ONiIgIY8SIEZf9GWRmZhq5ubn57sNutxsjR450tG3evDnfvV3SunVrQ5Ixbdq0y+5r3bq1U9vSpUsNScbLL79sHDhwwPDz8zO6d+/+j/cIAJdDBRBwU2fOnJEk+fv7F+j4L7/8UpKUkJDg1D548GBJyjdXsG7durrpppscn8uVK6datWrpwIEDhY75ry7NHfz000+Vl5dXoHOOHj2q7du3q0+fPgoJCXG0X3fddbr55psd9/lnDz/8sNPnm266SSdOnHD8DAvi3nvv1erVq5WSkqKVK1cqJSXlssO/0sV5gx4eF3995ubm6sSJE47h7e+//77A17Tb7erbt2+Bjr3lllv00EMPaeTIkYqNjZW3t7feeuutAl8LAP6MBBBwUwEBAZKks2fPFuj4X375RR4eHqpRo4ZTe0REhIKCgvTLL784tVeuXDlfH8HBwTp16lQhI87v7rvvVosWLTRgwACFh4erZ8+e+vjjj/82GbwUZ61atfLtq1Onjv744w9lZGQ4tf/1XoKDgyXJpXvp1KmT/P399dFHH2nWrFlq2rRpvp/lJXl5eRo/fryuueYa2e12lS1bVuXKldOOHTt0+vTpAl+zQoUKLj3w8frrryskJETbt2/XG2+8obCwsAKfCwB/RgIIuKmAgABFRkbqxx9/dOm8vz6EcSWlSpW6bLthGIW+xqX5aZf4+Pho7dq1Wr58ue6//37t2LFDd999t26++eZ8x/4b/+ZeLrHb7YqNjdXMmTP1ySefXLH6J0mvvPKKEhIS1KpVK3344YdaunSpli1bpmuvvbbAlU7p4s/HFdu2bdOxY8ckSTt37nTpXAD4MxJAwI3ddttt2r9/vzZu3PiPx0ZFRSkvL0979+51ak9NTVVaWprjid6iEBwc7PTE7CV/rTJKkoeHh9q3b69x48bpp59+0ujRo7Vy5UqtWrXqsn1fijM5OTnfvp9//llly5aVr6/vv7uBK7j33nu1bds2nT179rIPzlwyf/58tW3bVtOnT1fPnj11yy23KCYmJt/PpKDJeEFkZGSob9++qlu3rh588EGNGTNGmzdvLrL+AVgLCSDgxp555hn5+vpqwIABSk1Nzbd///79mjhxoqSLQ5iS8j2pO27cOElS586diyyu6tWr6/Tp09qxY4ej7ejRo/rkk0+cjjt58mS+cy8tiPzXpWkuKV++vBo0aKCZM2c6JVQ//vijvv76a8d9Foe2bdtq1KhRmjRpkiIiIq54XKlSpfJVF+fNm6fff//dqe1Sonq5ZNlVzz77rA4fPqyZM2dq3LhxqlKliuLi4q74cwSAv8NC0IAbq169umbPnq27775bderUcXoTyDfffKN58+apT58+kqTrr79ecXFxevvtt5WWlqbWrVvru+++08yZM9W9e/crLjFSGD179tSzzz6r22+/XY8//rjOnTunqVOnqmbNmk4PQYwcOVJr165V586dFRUVpWPHjmnKlCmqWLGiWrZsecX+//e//6ljx46Kjo5W//79df78eb355psKDAzU8OHDi+w+/srDw0MvvvjiPx532223aeTIkerbt69uvPFG7dy5U7NmzVK1atWcjqtevbqCgoI0bdo0+fv7y9fXV82aNVPVqlVdimvlypWaMmWKhg0b5liWJikpSW3atNHQoUM1ZswYl/oDAJaBAf4D9uzZYzzwwANGlSpVDC8vL8Pf399o0aKF8eabbxqZmZmO43JycowRI0YYVatWNTw9PY1KlSoZQ4YMcTrGMC4uA9O5c+d81/nr8iNXWgbGMAzj66+/NurVq2d4eXkZtWrVMj788MN8y8CsWLHC6NatmxEZGWl4eXkZkZGRxj333GPs2bMn3zX+ulTK8uXLjRYtWhg+Pj5GQECA0aVLF+Onn35yOubS9f66zExSUpIhyTh48OAVf6aG4bwMzJVcaRmYwYMHG+XLlzd8fHyMFi1aGBs3brzs8i2ffvqpUbduXaN06dJO99m6dWvj2muvvew1/9zPmTNnjKioKKNRo0ZGTk6O03GDBg0yPDw8jI0bN/7tPQDAX9kMw4VZ0gAAAPjPYw4gAACAxZAAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxZTIN4H4NHzU7BCAfE5tnmR2CADg1rxNzEqKM3c4v839fv9TAQQAALCYElkBBAAAcInNWjUxEkAAAACbzewIriprpbsAAACgAggAAGC1IWBr3S0AAACoAAIAADAHEAAAACUaFUAAAADmAAIAAKAkowIIAABgsTmAJIAAAAAMAQMAAKAkowIIAABgsSFgKoAAAAAWQwUQAACAOYAAAAAoyagAAgAAMAcQAAAAJRkVQAAAAOYAAgAAWIzNVnybC6pUqSKbzZZvi4+PlyRlZmYqPj5eoaGh8vPzU48ePZSamury7ZIAAgAAuInNmzfr6NGjjm3ZsmWSpDvvvFOSNGjQIH3++eeaN2+e1qxZoyNHjig2Ntbl6zAEDAAA4CZDwOXKlXP6/Oqrr6p69epq3bq1Tp8+renTp2v27Nlq166dJCkpKUl16tTRpk2b1Lx58wJfxz3uFgAAoITKysrSmTNnnLasrKx/PC87O1sffvih+vXrJ5vNpq1btyonJ0cxMTGOY2rXrq3KlStr48aNLsVEAggAAGDzKLYtMTFRgYGBTltiYuI/hrRo0SKlpaWpT58+kqSUlBR5eXkpKCjI6bjw8HClpKS4dLsMAQMAABSjIUOGKCEhwanNbrf/43nTp09Xx44dFRkZWeQxkQACAAB4FN9C0Ha7vUAJ35/98ssvWr58uRYuXOhoi4iIUHZ2ttLS0pyqgKmpqYqIiHCpf4aAAQAA3ExSUpLCwsLUuXNnR1vjxo3l6empFStWONqSk5N1+PBhRUdHu9Q/FUAAAAA3eQpYkvLy8pSUlKS4uDiVLv1/qVpgYKD69++vhIQEhYSEKCAgQI899piio6NdegJYIgEEAABwq3cBL1++XIcPH1a/fv3y7Rs/frw8PDzUo0cPZWVlqUOHDpoyZYrL17AZhmEURbDuxKfho2aHAORzavMks0MAALfmbWJZyqf9K8XW9/kVzxdb34VFBRAAAMCNhoCvBmvdLQAAAKgAAgAAuNMcwKuBCiAAAIDFUAEEAABgDiAAAABKMiqAAAAAFpsDSAIIAADAEDAAAABKMiqAAAAAFhsCpgIIAABgMVQAAQAAmAMIAACAkowKIAAAAHMAAQAAUJJRAQQAALDYHEASQAAAAIslgNa6WwAAAFABBAAA4CEQAAAAlGhUAAEAAJgDCAAAgJKMCiAAAABzAAEAAFCSUQEEAACw2BxAEkAAAACGgAEAAFCSUQEEAACWZ6MCCAAAgJLM9AQwJydH1atX1+7du80OBQAAWJTNZiu2zR2ZngB6enoqMzPT7DAAAAAsw/QEUJLi4+P12muv6cKFC2aHAgAArMhWjJsbcouHQDZv3qwVK1bo66+/Vv369eXr6+u0f+HChSZFBgAAUPK4RQIYFBSkHj16mB0GAACwKHedq1dc3CIBTEpKMjsEAABgYSSAJjp+/LiSk5MlSbVq1VK5cuVMjggAAKDkcYuHQDIyMtSvXz+VL19erVq1UqtWrRQZGan+/fvr3LlzZocHAABKOJaBMUFCQoLWrFmjzz//XGlpaUpLS9Onn36qNWvWaPDgwWaHBwAAUKK4xRDwggULNH/+fLVp08bR1qlTJ/n4+Oiuu+7S1KlTzQsOAACUeO5aqSsublEBPHfunMLDw/O1h4WFMQRczH7+YoTOb5uUbxv/3F35jl00aaDOb5ukLm2uMyFSQJo7e5Y63txOTRvWV6+ed2rnjh1mhwSL4zuJ/yq3SACjo6M1bNgwpzeCnD9/XiNGjFB0dLSJkZV8Le/7n6rEDHFsnR5+U5K0cNk2p+Me69VWhmFGhMBFS776Uq+PSdRDj8Rr7rxPVKtWbQ18qL9OnDhhdmiwKL6TJYzFFoJ2iwRw4sSJ2rBhgypWrKj27durffv2qlSpkr755htNnDjR7PBKtD9OpSv1xFnH1ummetp/+LjWbd3rOOa6mhX0xP3t9PDwD02MFFb3wcwkxd5xl7rf3kPVa9TQi8NGyNvbW4sWLjA7NFgU30n8l7nFHMB69epp7969mjVrln7++WdJ0j333KNevXrJx8fH5Oisw7N0KfXs1FRvfLjS0ebj7akZiX305KsfK/XEWROjg5XlZGdr90+71P+BhxxtHh4eat78Ru34YdvfnAkUD76TJY/V5gC6RQIoSWXKlNEDDzxgdhiW1rXtdQry99GHn3/raBszuIc2/XBQi1fvNDEyWN2ptFPKzc1VaGioU3toaKgOHjxgUlSwMr6T+K9zmwRw7969WrVqlY4dO6a8vDynfS+99NIVz8vKylJWVpZTm5GXK5tHqWKJsySL636jlm74SUePn5YkdW5dX21uqKnmPV81OTIAAIoXFUATvPPOOxo4cKDKli2riIgIp/8JNpvtbxPAxMREjRgxwqmtVHhTeZa/odjiLYkqlw9Wu2a11POpdxxtbZrWVLWKZZWy9n9Ox855fYA2bNuvDg8wPxNXR3BQsEqVKpVvcv2JEydUtmxZk6KClfGdLHlIAE3w8ssva/To0Xr22WddPnfIkCFKSEhwagu7yfV+rO7+rtE6dvKsvlq3y9H2etLXSvrkG6fjts5/Qc+MXaAv1vx4tUOEhXl6ealO3Wv17aaNatc+RpKUl5enb7/dqJ733GdydLAivpP4r3OLBPDUqVO68847C3Wu3W6X3W53amP41zU2m029uzXXrMXfKjf3/4bfLz0Z/Fe/Hj2lX46wzAGurvvj+mro88/q2mvrqV796/ThBzN1/vx5db891uzQYFF8J0sWKoAmuPPOO/X111/r4YcfNjsUS2rXrJYqlw/RzEWbzA4FuKJbO3bSqZMnNWXSG/rjj+OqVbuOprz1rkIZboNJ+E7iv8xmGOYv75uYmKhx48apc+fOql+/vjw9PZ32P/744y7159Pw0aIMDygSpzZPMjsEAHBr3iaWpULj5hRb3ydm3lNsfReWWySAVatWveI+m82mAwdce6SeBBDuiAQQAP4eCeDV4xZvAjl48OAVN1eTPwAAAFfZbLZi21z1+++/67777lNoaKh8fHxUv359bdmyxbHfMAy99NJLKl++vHx8fBQTE6O9e/f+TY/5uUUCCAAAgIsPxrZo0UKenp766quv9NNPP2ns2LEKDg52HDNmzBi98cYbmjZtmr799lv5+vqqQ4cOyszMLPB1TCu2JiQkaNSoUfL19c23jMtfjRs37ipFBQAArMhdngJ+7bXXVKlSJSUlJTna/jxVzjAMTZgwQS+++KK6desmSXr//fcVHh6uRYsWqWfPngW6jmkJ4LZt25STk+P4MwAAgFmKMwG83FvLLreMnSR99tln6tChg+68806tWbNGFSpU0COPPOJ4Xe7BgweVkpKimJgYxzmBgYFq1qyZNm7c6P4J4KpVqy77ZwAAgJLkcm8tGzZsmIYPH57v2AMHDmjq1KlKSEjQ888/r82bN+vxxx+Xl5eX4uLilJKSIkkKDw93Oi88PNyxryBMXQewX79+/3iMzWbT9OnTr0I0AADAsopxBPhyby27XPVPuvhGmSZNmuiVV16RJDVs2FA//vijpk2bpri4uCKLydQEcMaMGYqKilLDhg3lBqvRAAAAFLkrDfdeTvny5VW3bl2ntjp16mjBggWSpIiICElSamqqypcv7zgmNTVVDRo0KHBMpiaAAwcO1Jw5c3Tw4EH17dtX9913n0JCQswMCQAAWJC7PATSokULJScnO7Xt2bNHUVFRki4+EBIREaEVK1Y4Er4zZ87o22+/1cCBAwt8HVOXgZk8ebKOHj2qZ555Rp9//rkqVaqku+66S0uXLqUiCAAALGfQoEHatGmTXnnlFe3bt0+zZ8/W22+/rfj4eEkXE9Unn3xSL7/8sj777DPt3LlTvXv3VmRkpLp3717g67jFm0Au+eWXXzRjxgy9//77unDhgnbt2iU/Pz+X++FNIHBHvAkEAP6emW8CiXhgfrH1nfLOHS4dv3jxYg0ZMkR79+5V1apVlZCQ4HgKWLq4FMywYcP09ttvKy0tTS1bttSUKVNUs2bNAl/D1CHgv/Lw8JDNZpNhGMrNzTU7HAAAgKvutttu02233XbF/TabTSNHjtTIkSMLfQ3T3wSSlZWlOXPm6Oabb1bNmjW1c+dOTZo0SYcPHy5U9Q8AAMBV7vQquKvB1ArgI488orlz56pSpUrq16+f5syZo7Jly5oZEgAAsCB3TdSKi6kJ4LRp01S5cmVVq1ZNa9as0Zo1ay573MKFC69yZAAAACWXqQlg7969LZdxAwAAN2SxdMT0haABAABwdbnVU8AAAABmsNqIpOlPAQMAAODqogIIAAAsjwogAAAASjQqgAAAwPKsVgEkAQQAALBW/scQMAAAgNVQAQQAAJZntSFgKoAAAAAWQwUQAABYHhVAAAAAlGhUAAEAgOVRAQQAAECJRgUQAABYntUqgCSAAAAA1sr/GAIGAACwGiqAAADA8qw2BEwFEAAAwGKoAAIAAMujAggAAIASjQogAACwPIsVAKkAAgAAWA0VQAAAYHlWmwNIAggAACzPYvkfQ8AAAABWQwUQAABYntWGgKkAAgAAWAwVQAAAYHkWKwBSAQQAALAaKoAAAMDyPDysVQKkAggAAGAxVAABAIDlWW0OIAkgAACwPJaBAQAAQIlGBRAAAFiexQqAVAABAACshgogAACwPOYAAgAAoESjAggAACyPCiAAAABKNCqAAADA8ixWACQBBAAAYAgYAAAAJRoVQAAAYHkWKwBSAQQAALAaKoAAAMDymAMIAACAEo0EEAAAWJ7NVnybK4YPHy6bzea01a5d27E/MzNT8fHxCg0NlZ+fn3r06KHU1FSX75cEEAAAwI1ce+21Onr0qGNbv369Y9+gQYP0+eefa968eVqzZo2OHDmi2NhYl6/BHEAAAGB57jQHsHTp0oqIiMjXfvr0aU2fPl2zZ89Wu3btJElJSUmqU6eONm3apObNmxf4GlQAAQAAilFWVpbOnDnjtGVlZV3x+L179yoyMlLVqlVTr169dPjwYUnS1q1blZOTo5iYGMextWvXVuXKlbVx40aXYiIBBAAAlleccwATExMVGBjotCUmJl42jmbNmmnGjBlasmSJpk6dqoMHD+qmm27S2bNnlZKSIi8vLwUFBTmdEx4erpSUFJfulyFgAABgecU5BDxkyBAlJCQ4tdnt9sse27FjR8efr7vuOjVr1kxRUVH6+OOP5ePjU2QxUQEEAAAoRna7XQEBAU7blRLAvwoKClLNmjW1b98+RUREKDs7W2lpaU7HpKamXnbO4N8hAQQAAJbnLsvA/FV6err279+v8uXLq3HjxvL09NSKFSsc+5OTk3X48GFFR0e71G+JHAIeNnaQ2SEA+Rw4lmF2CICTFQePmR0C4OSxFlXNDsF0Tz31lLp06aKoqCgdOXJEw4YNU6lSpXTPPfcoMDBQ/fv3V0JCgkJCQhQQEKDHHntM0dHRLj0BLJXQBBAAAMAV7rIMzG+//aZ77rlHJ06cULly5dSyZUtt2rRJ5cqVkySNHz9eHh4e6tGjh7KystShQwdNmTLF5euQAAIAALiJuXPn/u1+b29vTZ48WZMnT/5X1yEBBAAAlucmBcCrhodAAAAALIYKIAAAsDx3mQN4tZAAAgAAy7NY/scQMAAAgNVQAQQAAJZntSFgKoAAAAAWQwUQAABYHhVAAAAAlGhUAAEAgOVZrABIBRAAAMBqqAACAADLs9ocQBJAAABgeRbL/xgCBgAAsBoqgAAAwPKsNgRMBRAAAMBiqAACAADLs1gBkAogAACA1VABBAAAludhsRIgFUAAAACLoQIIAAAsz2IFQBJAAAAAloEBAABAiUYFEAAAWJ6HtQqAVAABAACshgogAACwPOYAAgAAoESjAggAACzPYgVAKoAAAABWQwUQAABYnk3WKgGSAAIAAMtjGRgAAACUaFQAAQCA5bEMDAAAAEo0KoAAAMDyLFYApAIIAABgNVQAAQCA5XlYrARIBRAAAMBiqAACAADLs1gBkAQQAACAZWAAAABQorlFAvjBBx+oRYsWioyM1C+//CJJmjBhgj799FOTIwMAAFZgsxXf5o5MTwCnTp2qhIQEderUSWlpacrNzZUkBQUFacKECeYGBwAAUAKZngC++eabeuedd/TCCy+oVKlSjvYmTZpo586dJkYGAACswsNmK7bNHZmeAB48eFANGzbM126325WRkWFCRAAAACWb6Qlg1apVtX379nztS5YsUZ06da5+QAAAwHJsxbi5I9OXgUlISFB8fLwyMzNlGIa+++47zZkzR4mJiXr33XfNDg8AAKDEMT0BHDBggHx8fPTiiy/q3LlzuvfeexUZGamJEyeqZ8+eZocHAAAswGrrAJqeAEpSr1691KtXL507d07p6ekKCwszOyQAAGAhHtbK/8yfA9iuXTulpaVJksqUKeNI/s6cOaN27dqZGBkAAEDJZHoFcPXq1crOzs7XnpmZqXXr1pkQEQAAsBqrDQGbVgHcsWOHduzYIUn66aefHJ937Nihbdu2afr06apQoYJZ4QEAAJju1Vdflc1m05NPPuloy8zMVHx8vEJDQ+Xn56cePXooNTXVpX5NqwA2aNBANptNNpvtskO9Pj4+evPNN02IDAAAWI07FgA3b96st956S9ddd51T+6BBg/TFF19o3rx5CgwM1KOPPqrY2Fht2LChwH2blgAePHhQhmGoWrVq+u6771SuXDnHPi8vL4WFhTm9GQQAAMAq0tPT1atXL73zzjt6+eWXHe2nT5/W9OnTNXv2bEcBLSkpSXXq1NGmTZvUvHnzAvVvWgIYFRUlScrLyzMrBAAAAEnFOwcwKytLWVlZTm12u112u/2K58THx6tz586KiYlxSgC3bt2qnJwcxcTEONpq166typUra+PGjUWbAH722WcF6kySunbtWuBj/+ynn37S4cOH8z0QUtj+AAAA3EFiYqJGjBjh1DZs2DANHz78ssfPnTtX33//vTZv3pxvX0pKiry8vBQUFOTUHh4erpSUlALHVKAEsHv37gXqzGazKTc3t8AXl6QDBw7o9ttv186dO2Wz2WQYhqMvSS73BwAA4KriXAdwyJAhSkhIcGq7UvXv119/1RNPPKFly5bJ29u72GIq0FPAeXl5BdoKk6w98cQTqlq1qo4dO6YyZcpo165dWrt2rZo0aaLVq1e73B8AAICrLj2YWhyb3W5XQECA03alBHDr1q06duyYGjVqpNKlS6t06dJas2aN3njjDZUuXVrh4eHKzs52rKF8SWpqqiIiIgp8v6avA7hx40atXLlSZcuWlYeHhzw8PNSyZUslJibq8ccf17Zt28wOEQAA4Kpo3769du7c6dTWt29f1a5dW88++6wqVaokT09PrVixQj169JAkJScn6/Dhw4qOji7wdQqVAGZkZGjNmjWXnbP3+OOPu9RXbm6u/P39JUlly5bVkSNHVKtWLUVFRSk5Obkw4QEAALjEXVaB8ff3V7169ZzafH19FRoa6mjv37+/EhISFBISooCAAD322GOKjo4u8AMgUiESwG3btqlTp046d+6cMjIyFBISoj/++MPxGjdXE8B69erphx9+UNWqVdWsWTONGTNGXl5eevvtt1WtWjVXwwMAACjRxo8fLw8PD/Xo0UNZWVnq0KGDpkyZ4lIfLieAgwYNUpcuXTRt2jQFBgZq06ZN8vT01H333acnnnjC1e704osvKiMjQ5I0cuRI3XbbbbrpppsUGhqqjz76yOX+AAAAXOXhjitB/39/fSbC29tbkydP1uTJkwvdp8sJ4Pbt2/XWW2/Jw8NDpUqVUlZWlqpVq6YxY8YoLi5OsbGxLvXXoUMHx59r1Kihn3/+WSdPnlRwcLDl3ssHAABwNbj8LmBPT095eFw8LSwsTIcPH5YkBQYG6tdff3Wpr5ycHJUuXVo//vijU3tISAjJHwAAuGpstuLb3JHLFcCGDRtq8+bNuuaaa9S6dWu99NJL+uOPP/TBBx/km7T4Tzw9PVW5cmXW+gMAALiKXK4AvvLKKypfvrwkafTo0QoODtbAgQN1/Phxvf322y4H8MILL+j555/XyZMnXT4XAACgKBTnOoDuyOUKYJMmTRx/DgsL05IlS/5VAJMmTdK+ffsUGRmpqKgo+fr6Ou3//vvv/1X/AAAAcGb6QtAFfc0cAABAcXHTQl2xcTkBrFq16t+WMw8cOOBSf8OGDXM1BBShn9d8oZ/XfaH0E6mSpKDyUWrQ6R5VrNdUWRlntW3xh/r9p++Vceq4vP0CVfn6aDXqer+8fHz/oWeg8Hb9sFWLPnpf+/fs1qkTf+i5UWPVrGVbx/65M6Zp/cqv9cfxFJUu7anqNeuoV/941axb38SoUZLtXLVYP65arDN/HJMkhVSorBu69FLUdU0lSRdysrVh7tva890a5V3IUaV6jdXmvkdVJjDYzLDhAndeBqY4uJwAPvnkk06fc3JytG3bNi1ZskRPP/10oYJIS0vT/PnztX//fj399NMKCQnR999/r/DwcFWoUKFQfaJgygSXVePufRUQFikZhvZtWqEV00ap6/NvSoahc2kn1LTHAAWVr6z0E6naOGeSzp0+oXYPvmB26CjBMjMzVaV6TbXv2E2vvfRUvv2RFaP0wBPPKrx8BWVnZenz+bM04pl4TfnwUwUG8Rcuip5fcFlF39FPQeEVZBiGft6wXF+8OUJ3D5+k0ApVtH7OWzq04zt1fOQFefn4as2syfpy8ijd8fw4s0MHLsvlBPBKiz1PnjxZW7ZscTmAHTt2KCYmRoGBgTp06JAeeOABhYSEaOHChTp8+LDef/99l/tEwVW+rpnT58bd4vTz2i90/ODPqtmig9o99KJjX0C58mrUNU5rZ/xPebm58ihV6mqHC4to3KyFGjdrccX9rWI6On3u+0iCln+5SL/s36PrGje7wllA4VVt4PyKregeffTj6sVK3f+z/ILL6ad1S3XLQ8+qYp0GkqSYfoM164UHlLJ/tyKq1zEhYrjKYgVA158CvpKOHTtqwYIFLp+XkJCgPn36aO/evfL29na0d+rUSWvXri2q8FAAeXm5OrB5jS5kZyqs2uV/YeWcz5CndxmSP7iNnJwcfb14ocr4+qlKjZpmhwMLyMvL1Z5vVysnK0sR1evo+C97lZd7QZXqNnQcE1y+kvxDw5Syf7eJkQJXVmQPgcyfP18hISEun7d582a99dZb+dorVKiglJSUoggN/+Dk7wf1xf8GKzcnW552H7V7aKiCylfOd1xm+mlt/2qOarXseJlegKtr88a1GjdyiLKyMhUcWlbDX5+qAOZboRj98dtBLRg9SBf+/+/KTo8OVUiFKB3/9YA8SnvKXsbP6XifgCCdO33KpGjhKnddrqW4FGoh6D//kAzDUEpKio4fP+7yi4glyW6368yZM/na9+zZo3Llyv3j+VlZWcrKynJqu5CdpdJedpdjsarA8Irq9vwkZZ/P0KFt67Vu5lh1ShjjlARmnz+nZZOHKSiishre1svEaIGL6jdoqnHvztGZ02latvgTvT7iWb025X0FBbv+D1GgIIIjKuru4VOUfT5D+7as0/J3xyr22TFmhwUUissJYLdu3ZwSQA8PD5UrV05t2rRR7dq1XQ6ga9euGjlypD7++GNJFzPww4cP69lnn1WPHj3+8fzExESNGDHCqa1978cUE3f5uYrIr1Rpz4sPgUgqG3WN/ji0V7tWfqoWvR6TJOVkntPXk4bK015G7R4eKo9Spq8eBMjbx0flK1RW+QqVVavudXrkvm5a8eUi9ejVz+zQUEKVKu2poPCLvyvDqlyjYwf36Ifli3TNDa2VdyFHWefSnaqA58+k8RTwf0iRzYn7j3D5b/Lhw4cXaQBjx47VHXfcobCwMJ0/f16tW7dWSkqKoqOjNXr06H88f8iQIUpISHBqe+Ob34o0RqsxjDzlXciRdLHy9/WbL6pUaU/FPPKSSnt6mRwdcHl5hqGcnGyzw4CFGIah3As5Khd1jTxKldavP21XjSYtJUmnjv6qsyeO8QAI3JbLCWCpUqV09OhRhYWFObWfOHFCYWFhLr/XNzAwUMuWLdP69eu1Y8cOpaenq1GjRoqJiSnQ+Xa7XXa783Avw78Ft2VRkipe20S+IWHKyTynA5tXK2XvTt3y2KiLyd8bL+hCTpZa9X1a2efPKfv8OUmSt3+gPDx4EATF4/z5c0r5/VfH59Sjv+vgvmT5+QfIPyBI8z98V01btFZwSFmdPZ2mLxd9rJPHj+nG1jebGDVKsm/mv6eo+k3lH1pO2ZnntWfTKv2evENdE0bLXsZXdW/qoA0fvS1vX395+ZTR2llTFFG9DgngfwhzAP+BYRiXbc/KypKXV+GrQy1btlTLli0LfT4KJ/Psaa2bMVbnzpyUl7evgitU1S2PjVKFOo10dM8OHT+ULEla8FJ/p/PueDlJ/qHhZoQMC9if/JOGDnrQ8TlpysW11Np26KKHE57Xb78e0qphi3XmdJr8AwJVo9a1Gv3GdFWuWt2skFHCnT+TpuXv/k8Zp0/J7lNGoRWrqmvCaFW+tpEkqeU9D8lms+mrKaOUm5OjyvUaq/X9j5ocNVzhYa38TzbjShndX7zxxhuSpEGDBmnUqFHy8/u/eQ65ublau3atDh06pG3bthW4r4J4/PHHC3zsJa+u3O/yOUBx61o7wuwQACcrDh4zOwTAyWMtqpp27Sc//bnY+p7QzfVnJIpbgSuA48ePl3SxAjht2jSV+tM6cF5eXqpSpYqmTZvmUl+XHD9+XOfOnVNQUJCki28GKVOmjMLCwgqVAAIAALjCahXAAieABw8elCS1bdtWCxcuVHBw4Z9sutSXJM2ePVtTpkzR9OnTVatWLUlScnKyHnjgAT300EOFvgYAAAAuz+U5gKtWrSrSAIYOHar58+c7kj9JqlWrlsaPH6877rhDvXqx5hwAACheVnsIxOVlb3r06KHXXnstX/uYMWN05513uhzA0aNHdeHChXztubm5Sk1Ndbk/AAAA/D2XE8C1a9eqU6dO+do7duxYqHf3tm/fXg899JC+//57R9vWrVs1cODAAi8FAwAA8G942Ipvc0cuJ4Dp6emXXe7F09Pzsq90+yfvvfeeIiIi1KRJE8eafjfccIPCw8P17rvvutwfAAAA/p7LcwDr16+vjz76SC+99JJT+9y5c1W3bl2XAyhXrpy+/PJL7dmzR7t375bNZlPt2rVVs2ZNl/sCAAAoDItNAXQ9ARw6dKhiY2O1f/9+tWvXTpK0YsUKzZ49W/Pnzy90IDVr1tQ111wjyXoTMQEAgLk8LJZ7uDwE3KVLFy1atEj79u3TI488osGDB+v333/XypUrVaNGjUIF8f7776t+/fry8fGRj4+PrrvuOn3wwQeF6gsAAAB/z+UKoCR17txZnTt3liSdOXNGc+bM0VNPPaWtW7e6/C7gcePGaejQoXr00UfVokULSdL69ev18MMP648//tCgQYMKEyIAAECBuVwR+48rVAIoXXwaePr06VqwYIEiIyMVGxuryZMnu9zPm2++qalTp6p3796Otq5du+raa6/V8OHDSQABAACKmEsJYEpKimbMmKHp06frzJkzuuuuu5SVlaVFixYV6gEQ6eI6gDfeeGO+9htvvFFHjx4tVJ8AAACusNgUwIJXPLt06aJatWppx44dmjBhgo4cOaI333zzXwdQo0YNffzxx/naP/roI8dDIQAAACg6Ba4AfvXVV3r88cc1cODAIk3MRowYobvvvltr1651zAHcsGGDVqxYcdnEEAAAoKjxFPAVrF+/XmfPnlXjxo3VrFkzTZo0SX/88ce/DqBHjx769ttvVbZsWS1atEiLFi1S2bJl9d133+n222//1/0DAADAWYErgM2bN1fz5s01YcIEffTRR3rvvfeUkJCgvLw8LVu2TJUqVZK/v3+hgmjcuLE+/PDDQp0LAADwb1msAOj6U8++vr7q16+f1q9fr507d2rw4MF69dVXFRYWpq5duxZHjAAAAMWKdwG7oFatWhozZox+++03zZkzx6VzS5UqVaANAAAARavQ6wD+WalSpdS9e3d17969wOcYhqGoqCjFxcWpYcOGRREGAABAoVjtIZAiSQAL47vvvtP06dM1ceJEVa1aVf369VOvXr0UHBxsVkgAAACWYNqbT5o0aaKpU6fq6NGjSkhI0CeffKKKFSuqZ8+eWrZsmVlhAQAAC7LZim9zR6a/+s7b21v33XefVqxYoR9//FHHjh3TrbfeqpMnT5odGgAAQIlk2hDwn/3222+aMWOGZsyYoXPnzunpp59WQECA2WEBAACLcNendYuLaQlgdna2PvnkE02fPl3r1q1Tx44dNWHCBHXs2JGnfwEAAIqRaQlg+fLl5e/vr7i4OE2ZMkVhYWGSpIyMDKfjqAQCAIDiZpO1SoCmJYCnTp3SqVOnNGrUKL388sv59huGIZvNptzcXBOiAwAAVsIQ8FWyatUqsy4NAABgaaYlgK1btzbr0gAAAE6sVgE0fRkYAAAAXF1usQwMAACAmWzuumJzMaECCAAAYDFUAAEAgOUxBxAAAAAlGhVAAABgeRabAkgCCAAA4GGxDJAhYAAAADcxdepUXXfddQoICFBAQICio6P11VdfOfZnZmYqPj5eoaGh8vPzU48ePZSamurydUgAAQCA5XnYim9zRcWKFfXqq69q69at2rJli9q1a6du3bpp165dkqRBgwbp888/17x587RmzRodOXJEsbGxLt8vQ8AAAADFKCsrS1lZWU5tdrtddrs937FdunRx+jx69GhNnTpVmzZtUsWKFTV9+nTNnj1b7dq1kyQlJSWpTp062rRpk5o3b17gmKgAAgAAy7PZim9LTExUYGCg05aYmPiPMeXm5mru3LnKyMhQdHS0tm7dqpycHMXExDiOqV27tipXrqyNGze6dL9UAAEAAIrRkCFDlJCQ4NR2uerfJTt37lR0dLQyMzPl5+enTz75RHXr1tX27dvl5eWloKAgp+PDw8OVkpLiUkwkgAAAwPI8VHxPAV9puPdKatWqpe3bt+v06dOaP3++4uLitGbNmiKNiQQQAADAjXh5ealGjRqSpMaNG2vz5s2aOHGi7r77bmVnZystLc2pCpiamqqIiAiXrsEcQAAAYHnFOQfw38rLy1NWVpYaN24sT09PrVixwrEvOTlZhw8fVnR0tEt9UgEEAACW5y7vAh4yZIg6duyoypUr6+zZs5o9e7ZWr16tpUuXKjAwUP3791dCQoJCQkIUEBCgxx57TNHR0S49ASyRAAIAALiNY8eOqXfv3jp69KgCAwN13XXXaenSpbr55pslSePHj5eHh4d69OihrKwsdejQQVOmTHH5OiSAAADA8tzlVXDTp0//2/3e3t6aPHmyJk+e/K+uwxxAAAAAi6ECCAAALM9NCoBXDRVAAAAAi6ECCAAALM9d5gBeLVQAAQAALIYKIAAAsDyLFQBJAAEAAKw2JGq1+wUAALA8KoAAAMDybBYbA6YCCAAAYDFUAAEAgOVZq/5HBRAAAMByqAACAADLYyFoAAAAlGhUAAEAgOVZq/5HAggAAGC5N4EwBAwAAGAxVAABAIDlsRA0AAAASjQqgAAAwPKsVhGz2v0CAABYHhVAAABgecwBBAAAQIlGBRAAAFietep/VAABAAAshwogAACwPKvNASyRCeD9jSqZHQKQT2ZOrtkhAE5e/XC72SEATh5rUdW0a1ttSNRq9wsAAGB5JbICCAAA4AqrDQFTAQQAALAYKoAAAMDyrFX/owIIAABgOVQAAQCA5VlsCiAVQAAAAKuhAggAACzPw2KzAEkAAQCA5TEEDAAAgBKNCiAAALA8m8WGgKkAAgAAWAwVQAAAYHnMAQQAAECJRgUQAABYntWWgaECCAAAYDFUAAEAgOVZbQ4gCSAAALA8qyWADAEDAABYDBVAAABgeSwEDQAAgBKNCiAAALA8D2sVAKkAAgAAWA0VQAAAYHnMAQQAAIApEhMT1bRpU/n7+yssLEzdu3dXcnKy0zGZmZmKj49XaGio/Pz81KNHD6Wmprp0HRJAAABgeTZb8W2uWLNmjeLj47Vp0yYtW7ZMOTk5uuWWW5SRkeE4ZtCgQfr88881b948rVmzRkeOHFFsbKxL12EIGAAAWJ67DAEvWbLE6fOMGTMUFhamrVu3qlWrVjp9+rSmT5+u2bNnq127dpKkpKQk1alTR5s2bVLz5s0LdB0qgAAAAMUoKytLZ86ccdqysrIKdO7p06clSSEhIZKkrVu3KicnRzExMY5jateurcqVK2vjxo0FjokEEAAAWJ6Hrfi2xMREBQYGOm2JiYn/GFNeXp6efPJJtWjRQvXq1ZMkpaSkyMvLS0FBQU7HhoeHKyUlpcD3yxAwAABAMRoyZIgSEhKc2ux2+z+eFx8frx9//FHr168v8phIAAEAgOUV5xxAu91eoITvzx599FEtXrxYa9euVcWKFR3tERERys7OVlpamlMVMDU1VREREQXunyFgAAAAN2EYhh599FF98sknWrlypapWreq0v3HjxvL09NSKFSscbcnJyTp8+LCio6MLfB0qgAAAwPJcXa6luMTHx2v27Nn69NNP5e/v75jXFxgYKB8fHwUGBqp///5KSEhQSEiIAgIC9Nhjjyk6OrrATwBLJIAAAABuY+rUqZKkNm3aOLUnJSWpT58+kqTx48fLw8NDPXr0UFZWljp06KApU6a4dB0SQAAAYHluUgCUYRj/eIy3t7cmT56syZMnF/o6JIAAAMDyPNxlDPgq4SEQAAAAi6ECCAAALM9a9T8qgAAAAJZDBRAAAMBiJUAqgAAAABZDBRAAAFhecb4Kzh1RAQQAALAYKoAAAMDyLLYMIAkgAACAxfI/hoABAACshgogAACAxUqAVAABAAAshgogAACwPJaBAQAAQIlGBRAAAFie1ZaBoQIIAABgMVQAAQCA5VmsAEgCCAAAYLUM0G2GgPft26elS5fq/PnzkiTDMEyOCAAAoGQyPQE8ceKEYmJiVLNmTXXq1ElHjx6VJPXv31+DBw82OToAAGAFtmL8zx2ZngAOGjRIpUuX1uHDh1WmTBlH+913360lS5aYGBkAAEDJZPocwK+//lpLly5VxYoVndqvueYa/fLLLyZFBQAArIRlYK6yjIwMp8rfJSdPnpTdbjchIgAAgJLN9ATwpptu0vvvv+/4bLPZlJeXpzFjxqht27YmRgYAAKzCVoybOzJ9CHjMmDFq3769tmzZouzsbD3zzDPatWuXTp48qQ0bNpgdHgAAQIljegWwXr162rNnj1q2bKlu3bopIyNDsbGx2rZtm6pXr252eAAAwAosVgI0tQKYk5OjW2+9VdOmTdMLL7xgZigAAMDC3HW5luJiagXQ09NTO3bsMDMEAAAAyzF9CPi+++7T9OnTzQ4DAABYmM1WfJs7Mv0hkAsXLui9997T8uXL1bhxY/n6+jrtHzdunEmRAQAAlEymJ4A//vijGjVqJEnas2eP0z6bu6bNAACgRLFaxmF6Arhq1SqzQwAAALAU0+cAXrJv3z4tXbpU58+flyQZhmFyRAAAwDIstgyM6QngiRMn1L59e9WsWVOdOnXS0aNHJUn9+/fX4MGDTY4OAACg5DF9CHjQoEHy9PTU4cOHVadOHUf73XffrYSEBI0dO9bE6Kzpnu4dlHr0SL72bj3u1hPPvGhCRLCandu3asHsmdqXvFsnTxzXi6+M042t2jn2G4ahD6dP1ZLPFyrj7FnVrd9A8U89rwqVokyMGiVZQufaGnxbHae2fSln1XrEcklSuQC7hsbW0021w+TnXVr7U9P1xpJkfbkt/+9SuCerrQNoegL49ddfa+nSpapYsaJT+zXXXKNffvnFpKisbWrSHOXl5Tk+H9y/V08/9qBat+9gYlSwkszz51W1Rk3d0rm7Xn4hId/++bNm6LP5s5XwwihFlK+gD96doqEJj2jahwvlZbebEDGs4OcjZ9Rz4nrH5wu5/zdVaWJcYwWU8VTfqZt0MiNLtzetpGkDblDHxFXa9dtpM8IF/pbpCWBGRobKlCmTr/3kyZOy84vcFEHBIU6fZ8+crsiKlXR9oyYmRQSraRrdUk2jW152n2EYWjRvlnr2fkDRN7WVJA1+cZTu7dpeG9etUuuYW69mqLCQ3Nw8HT+Tddl9TaqFasic7dr+yylJ0sSvkvVAuxq6LiqIBPA/wmoLj5g+B/Cmm27S+++/7/hss9mUl5enMWPGqG3btiZGBuni6/qWL1msjl1uZ1keuIWUI7/r1Ik/1KBpM0ebr5+/atWtr90//mBiZCjpqob5aWvirfpm1C16s28TRQb7OPZtOXBCXZtUVFAZT9lsUtcmFWT39NDGPX+YGDFcYbFnQMyvAI4ZM0bt27fXli1blJ2drWeeeUa7du3SyZMntWHDBrPDs7wNa1YoPf2sOnTuZnYogCTp1MmLf6EGB4c6tQcFh+jUyRNmhAQL2HbolAa9v1X7U9MVFuCthM619cngVmo3aoUysi7o4Xc3a+qApto19jbl5ObpfHau+r/1rQ4dzzA7dOCyTE8A69Wrpz179mjSpEny9/dXenq6YmNjFR8fr/Lly//j+VlZWcrKyvpLm43h4yLy5Wef6IbolipbLszsUADANKt2pTr+vPv3M9p26JS+Hd1BXRpX0NxvftHTXeoowMdTd09Yr5PpWerQIFLTBjRV7Nh1+vnIGRMjR4G5a6mumJieAEpSYGCgXnjhhUKdm5iYqBEjRji1DXr2RQ1+bmhRhGZpKUeP6PvNmzTi1fFmhwI4BIeUlSSdOnVCIWXLOdrTTp1UtRo1zQoLFnPmfI4OpKarSjlfRZX1Vb+21dV25HLtOXpWkvTT72fUrEao+rSupufmbDc3WOAyTJ8DWKNGDQ0fPlx79+4t1PlDhgzR6dOnnbZHBz1TxFFa05LFixQUHKLmLVqZHQrgEBFZQcGhZfXDlu8cbecy0pX8007VqXe9iZHBSsrYSymqnK+OncmUj1cpSVLeX95fkJtnWO7Bgv8yWzH+545MTwDj4+P1xRdfqFatWmratKkmTpyolJSUAp9vt9sVEBDgtDH8++/l5eVpyeJFuqVzV5Uq7RaFYljI+XPntH/vz9q/92dJUurR37V/7886lnJUNptN3e/spbkz39Gm9at1cP9evf7yiwoNLed4KhgoakNj66n5NaGqGFJGTaqFaPpDzZWXZ2jR5t+0L+WsDh5L12v3NlCDqGBFlfXVQ+1rqFXtMC394ajZoQOXZTPc5J1re/bs0axZszRnzhwdPHhQbdu21X333afevXu73NfvadnFEKG1bN70jZ594iHNnPe5KlWuYnY4JUJmTq7ZIfxn7Ph+s557/IF87TEduyjhhVH/txD0ZwuUnn5W19ZvqEcGP6+KlVkI2hWtXlpidgj/GVP6N1WzGqEK9vXSyfRsfbf/hF779Cf98sfFhzyqlvPVkNuv1Q3VQ+VrL61DxzM0bdleLfjuV5Mj/2/5fertpl07OeVcsfVdKyL/cndmc5sE8M82bdqkgQMHaseOHcrNdf0vTRJAuCMSQLgbEkC4GxLAq8etxva+++47zZ49Wx999JHOnDmjO++80+yQAACABbjnTL3iY3oC+Neh33bt2um1115TbGys/Pz8zA4PAABYgcUyQNMTwNq1a6tp06aKj49Xz549FR4ebnZIAAAAJZrpCWBycrKuueYas8MAAAAW5q7LtRQX05eBueaaa5SWlqZ3331XQ4YM0cmTJyVJ33//vX7//XeTowMAACh5TE8Ad+zYoWuuuUavvfaaXn/9daWlpUmSFi5cqCFDhpgbHAAAsASbrfg2V61du1ZdunRRZGSkbDabFi1a5LTfMAy99NJLKl++vHx8fBQTE+PyCzVMTwAHDRqkvn37au/evfL29na0d+rUSWvXrjUxMgAAgKsvIyND119/vSZPnnzZ/WPGjNEbb7yhadOm6dtvv5Wvr686dOigzMzMAl/D9DmAW7Zs0dtvv52vvUKFCi69EQQAAKCw3GkGYMeOHdWxY8fL7jMMQxMmTNCLL76obt26SZLef/99hYeHa9GiRerZs2eBrmF6BdBut+vMmTP52vfs2aNy5cpd5gwAAID/jqysLJ05c8Zpy8rKKlRfBw8eVEpKimJiYhxtgYGBatasmTZu3FjgfkxPALt27aqRI0cqJydHkmSz2XT48GE9++yz6tGjh8nRAQAAS7AV35aYmKjAwECnLTExsVBhXhod/euyeeHh4S6NnJqeAI4dO1bp6ekKCwvT+fPn1bp1a1WvXl1+fn4aPXq02eEBAAALsBXjf0OGDNHp06edNrMfdDV9DmBgYKCWLVum9evXa8eOHUpPT1fjxo3Vvn17s0MDAAD41+x2u+x2e5H0FRERIUlKTU1V+fLlHe2pqalq0KBBgfsxrQK4ceNGLV682PG5ZcuW8vX11ZQpU3TPPffowQcfLPT4OAAAgCvcaRmYv1O1alVFRERoxYoVjrYzZ87o22+/VXR0dIH7MS0BHDlypHbt2uX4vHPnTj3wwAO6+eab9dxzz+nzzz8v9Pg4AADAf1V6erq2b9+u7du3S7r44Mf27dt1+PBh2Ww2Pfnkk3r55Zf12WefaefOnerdu7ciIyPVvXv3Al/DtCHg7du3a9SoUY7Pc+fO1Q033KB33nlHklSpUiUNGzZMw4cPNylCAABgFe60DMyWLVvUtm1bx+eEhARJUlxcnGbMmKFnnnlGGRkZevDBB5WWlqaWLVtqyZIlTusp/xPTEsBTp045PcGyZs0apzVvmjZtql9//dWM0AAAAEzTpk0bGYZxxf02m00jR47UyJEjC30N04aAw8PDdfDgQUlSdna2vv/+ezVv3tyx/+zZs/L09DQrPAAAYCXFuAyMOzItAezUqZOee+45rVu3TkOGDFGZMmV00003Ofbv2LFD1atXNys8AACAEsu0IeBRo0YpNjZWrVu3lp+fn2bOnCkvLy/H/vfee0+33HKLWeEBAAALsblrqa6YmJYAli1bVmvXrtXp06fl5+enUqVKOe2fN2+e/Pz8TIoOAABYSVEv1+Lu3GIh6MsJCQm5ypEAAABYg+kJIAAAgNksVgA0/13AAAAAuLqoAAIAAMuz2hxAKoAAAAAWQwUQAADAYrMAqQACAABYDBVAAABgeVabA0gCCAAALM9i+R9DwAAAAFZDBRAAAFie1YaAqQACAABYDBVAAABgeTaLzQKkAggAAGAxVAABAACsVQCkAggAAGA1VAABAIDlWawASAIIAADAMjAAAAAo0agAAgAAy2MZGAAAAJRoVAABAACsVQCkAggAAGA1VAABAIDlWawASAUQAADAaqgAAgAAy7PaOoAkgAAAwPJYBgYAAAAlGhVAAABgeVYbAqYCCAAAYDEkgAAAABZDAggAAGAxzAEEAACWxxxAAAAAlGhUAAEAgOVZbR1AEkAAAGB5DAEDAACgRKMCCAAALM9iBUAqgAAAAFZDBRAAAMBiJUAqgAAAABZDBRAAAFie1ZaBoQIIAABgMVQAAQCA5bEOIAAAAEo0KoAAAMDyLFYAJAEEAACwWgbIEDAAAIDFkAACAADLsxXjf4UxefJkValSRd7e3mrWrJm+++67Ir1fEkAAAAA38tFHHykhIUHDhg3T999/r+uvv14dOnTQsWPHiuwaJIAAAMDybLbi21w1btw4PfDAA+rbt6/q1q2radOmqUyZMnrvvfeK7H5JAAEAAIpRVlaWzpw547RlZWVd9tjs7Gxt3bpVMTExjjYPDw/FxMRo48aNRRZTiXwKuEKQl9khlAhZWVlKTEzUkCFDZLfbzQ4H4DtZxH6fervZIZQIfC9LBu9izIiGv5yoESNGOLUNGzZMw4cPz3fsH3/8odzcXIWHhzu1h4eH6+effy6ymGyGYRhF1htKlDNnzigwMFCnT59WQECA2eEAfCfhlvhe4p9kZWXlq/jZ7fbL/oPhyJEjqlChgr755htFR0c72p955hmtWbNG3377bZHEVCIrgAAAAO7iSsne5ZQtW1alSpVSamqqU3tqaqoiIiKKLCbmAAIAALgJLy8vNW7cWCtWrHC05eXlacWKFU4VwX+LCiAAAIAbSUhIUFxcnJo0aaIbbrhBEyZMUEZGhvr27Vtk1yABxBXZ7XYNGzaMSc1wG3wn4Y74XqKo3X333Tp+/LheeuklpaSkqEGDBlqyZEm+B0P+DR4CAQAAsBjmAAIAAFgMCSAAAIDFkAACAABYDAkg1KZNGz355JNmhwFcVpUqVTRhwgSzwwCAEoUEsITq06ePbDabHn744Xz74uPjZbPZ1KdPH0nSwoULNWrUqKscIf7rVq9eLZvNpuDgYGVmZjrt27x5s2w2m2yFeQu6SQ4dOiSbzabt27ebHQqKyfHjxzVw4EBVrlxZdrtdERER6tChgzZs2GB2aMBVRwJYglWqVElz587V+fPnHW2ZmZmaPXu2Kleu7GgLCQmRv79/scaSnZ1drP3DPP7+/vrkk0+c2qZPn+70HTMT3z1c0qNHD23btk0zZ87Unj179Nlnn6lNmzY6ceKEaTHx/YRZSABLsEaNGqlSpUpauHCho23hwoWqXLmyGjZs6Gj76xBwlSpV9Morr6hfv37y9/dX5cqV9fbbbzv1vXPnTrVr104+Pj4KDQ3Vgw8+qPT0dMf+Pn36qHv37ho9erQiIyNVq1at4rtRmCouLk7vvfee4/P58+c1d+5cxcXF5Tt2wYIFuvbaa2W321WlShWNHTvWaf+xY8fUpUsX+fj4qGrVqpo1a1a+PtLS0jRgwACVK1dOAQEBateunX744QfH/uHDh6tBgwZ69913VbVqVXl7e0uSlixZopYtWyooKEihoaG67bbbtH//fsd5VatWlSQ1bNhQNptNbdq0cex79913VadOHXl7e6t27dqaMmVK4X5YME1aWprWrVun1157TW3btlVUVJRuuOEGDRkyRF27dnUcc6Xv1p49e2Sz2fTzzz879Tt+/HhVr17d8fnHH39Ux44d5efnp/DwcN1///36448/HPvbtGmjRx99VE8++aTKli2rDh06FOg8oKiRAJZw/fr1U1JSkuPze++9V6CVxMeOHasmTZpo27ZteuSRRzRw4EAlJydLkjIyMtShQwcFBwdr8+bNmjdvnpYvX65HH33UqY8VK1YoOTlZy5Yt0+LFi4v2xuA27r//fq1bt06HDx+WdDHJq1Kliho1auR03NatW3XXXXepZ8+e2rlzp4YPH66hQ4dqxowZjmP69OmjX3/9VatWrdL8+fM1ZcoUHTt2zKmfO++8U8eOHdNXX32lrVu3qlGjRmrfvr1OnjzpOGbfvn1asGCBFi5c6BjSzcjIUEJCgrZs2aIVK1bIw8NDt99+u/Ly8iRJ3333nSRp+fLlOnr0qOMfTrNmzdJLL72k0aNHa/fu3XrllVc0dOhQzZw5s0h/jihefn5+8vPz06JFi5SVlXXZY/7uu1WzZk01adIk3z9KZs2apXvvvVfSxQSyXbt2atiwobZs2aIlS5YoNTVVd911l9M5M2fOlJeXlzZs2KBp06YV+DygSBkokeLi4oxu3boZx44dM+x2u3Ho0CHj0KFDhre3t3H8+HGjW7duRlxcnGEYhtG6dWvjiSeecJwbFRVl3HfffY7PeXl5RlhYmDF16lTDMAzj7bffNoKDg4309HTHMV988YXh4eFhpKSkOK4fHh5uZGVlFf/NwhSrVq0yJBmnTp0yunfvbowYMcIwDMNo27atMXHiROOTTz4x/vwr5t577zVuvvlmpz6efvppo27duoZhGEZycrIhyfjuu+8c+3fv3m1IMsaPH28YhmGsW7fOCAgIMDIzM536qV69uvHWW28ZhmEYw4YNMzw9PY1jx479bfzHjx83JBk7d+40DMMwDh48aEgytm3blq/v2bNnO7WNGjXKiI6O/tv+4X7mz59vBAcHG97e3saNN95oDBkyxPjhhx8MwyjYd2v8+PFG9erVHfsufWd3795tGMbF78Utt9zidP6vv/5qSDKSk5MNw7j4+7Zhw4ZOxxTkPKCoUQEs4cqVK6fOnTtrxowZSkpKUufOnVW2bNl/PO+6665z/NlmsykiIsJRidm9e7euv/56+fr6Oo5p0aKF8vLyHFVCSapfv768vLyK8G7grvr166cZM2bowIED2rhxo3r16pXvmN27d6tFixZObS1atNDevXuVm5ur3bt3q3Tp0mrcuLFjf+3atRUUFOT4/MMPPyg9PV2hoaGOio6fn58OHjzoNJwbFRWlcuXKOV1r7969uueee1StWjUFBASoSpUqkuSoXF5ORkaG9u/fr/79+ztd7+WXX3a6Hv4bevTooSNHjuizzz7TrbfeqtWrV6tRo0aaMWNGgb5bPXv21KFDh7Rp0yZJF6t/jRo1Uu3atSVd/H6uWrXK6fxL+/78ffnzd9yV84CixLuALaBfv36O4dnJkycX6BxPT0+nzzabzTFUVlB/ThBRsnXs2FEPPvig+vfvry5duig0NLRYrpOenq7y5ctr9erV+fb9OVG83HevS5cuioqK0jvvvKPIyEjl5eWpXr16fzsJ/9K81nfeeUfNmjVz2leqVKnC3QRM5e3trZtvvlk333yzhg4dqgEDBmjYsGF65JFH/vG7FRERoXbt2mn27Nlq3ry5Zs+erYEDBzqOS09PV5cuXfTaa6/l66N8+fKOP//1+1nQ84CiRAJoAbfeequys7Nls9kcE47/jTp16mjGjBnKyMhw/CLbsGGDPDw8eNjDokqXLq3evXtrzJgx+uqrry57TJ06dfItt7FhwwbVrFlTpUqVUu3atXXhwgVt3bpVTZs2lSQlJycrLS3NcXyjRo2UkpKi0qVLOyp4BXHixAklJyfrnXfe0U033SRJWr9+vdMxl6rVubm5jrbw8HBFRkbqwIEDl61q4r+vbt26WrRoUYG/W7169dIzzzyje+65RwcOHFDPnj0d+xo1auSYA1u6dMH/ei3secC/wRCwBZQqVUq7d+/WTz/9VCRVi169esnb21txcXH68ccftWrVKj322GO6//77FR4eXgQR479o1KhROn78+BX/kTF48GCtWLFCo0aN0p49ezRz5kxNmjRJTz31lCSpVq1auvXWW/XQQw/p22+/1datWzVgwAD5+Pg4+oiJiVF0dLS6d++ur7/+WocOHdI333yjF154QVu2bLlibMHBwQoNDdXbb7+tffv2aeXKlUpISHA6JiwsTD4+Po4J+KdPn5YkjRgxQomJiXrjjTe0Z88e7dy5U0lJSRo3bty//ZHhKjpx4oTatWunDz/8UDt27NDBgwc1b948jRkzRt26dSvwdys2NlZnz57VwIED1bZtW0VGRjr2xcfH6+TJk7rnnnu0efNm7d+/X0uXLlXfvn2d/mHxV4U9D/g3SAAtIiAgQAEBAUXSV5kyZbR06VKdPHlSTZs21R133KH27dtr0qRJRdI//pu8vLxUtmzZKy7+3KhRI3388ceaO3eu6tWrp5deekkjR450LEguSUlJSYqMjFTr1q0VGxurBx98UGFhYY79NptNX375pVq1aqW+ffuqZs2a6tmzp3755Ze//ceHh4eH5s6dq61bt6pevXoaNGiQ/ve//zkdU7p0ab3xxht66623FBkZqW7dukmSBgwYoHfffVdJSUmqX7++WrdurRkzZjiWjcF/g5+fn5o1a6bx48erVatWqlevnoYOHaoHHnhAkyZNKvB3y9/fX126dNEPP/yQryocGRmpDRs2KDc3V7fccovq16+vJ598UkFBQfLwuPJft4U9D/g3bIZhGGYHAQAAgKuHf1oAAABYDAkgAACAxZAAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxZAAAnBbffr0Uffu3R2f27RpoyeffPKqx7F69WrZbDan9xIDwH8ZCSAAl/Xp00c2m002m01eXl6qUaOGRo4cqQsXLhTrdRcuXKhRo0YV6FiSNgC4stJmBwDgv+nWW29VUlKSsrKy9OWXXyo+Pl6enp4aMmSI03HZ2dny8vIqkmuGhIQUST8AYHVUAAEUit1uV0REhKKiojRw4EDFxMTos88+cwzbjh49WpGRkapVq5Yk6ddff9Vdd92loKAghYSEqFu3bjp06JCjv9zcXCUkJCgoKEihoaF65pln9NdXlf91CDgrK0vPPvusKlWqJLvdrho1amj69Ok6dOiQ2rZtK0kKDg6WzWZTnz59JEl5eXlKTExU1apV5ePjo+uvv17z5893us6XX36pmjVrysfHR23btnWKEwBKAhJAAEXCx8dH2dnZkqQVK1YoOTlZy5Yt0+LFi5WTk6MOHTrI399f69at04YNG+Tn56dbb73Vcc7YsWM1Y8YMvffee1q/fr1OnjypTz755G+v2bt3b82ZM0dvvPGGdu/erbfeekt+fn6qVKmSFixYIElKTk7W0aNHNXHiRElSYmKi3n//fU2bNk27du3SoEGDdN9992nNmjWSLiaqsbGx6tKli7Zv364BAwboueeeK64fGwCYgiFgAP+KYRhasWKFli5dqscee0zHjx+Xr6+v3n33XcfQ74cffqi8vDy9++67stlskqSkpCQFBQVp9erVuuWWWzRhwgQNGTJEsbGxkqRp06Zp6dKlV7zunj179PHHH2vZsmWKiYmRJFWrVs2x/9JwcVhYmIKCgiRdrBi+8sorWr58uaKjox3nrF+/Xm+99ZZat26tqVOnqnr16ho7dqwkqVatWtq5c6dee+21IvypAYC5SAABFMrixYvl5+ennJwc5eXl6d5779Xw4cMVHx+v+vXrO837++GHH7Rv3z75+/s79ZGZman9+/fr9OnTOnr0qJo1a+bYV7p0aTVp0iTfMPAl27dvV6lSpdS6desCx7xv3z6dO3dON998s1N7dna2GjZsKEnavXu3UxySHMkiAJQUJIAACqVt27aaOnWqvLy8FBkZqdKl/+/Xia+vr9Ox6enpaty4sWbNmpWvn3LlyhXq+j4+Pi6fk56eLkn64osvVKFCBad9dru9UHEAwH8RCSCAQvH19VWNGjUKdGyjRo300UcfKSwsTAEBAZc9pnz58vr222/VqlUrSdKFCxe0detWNWrU6LLH169fX3l5eVqzZo1jCPjPLlUgc3NzHW1169aV3W7X4cOHr1g5rFOnjj777DOntk2bNv3zTQLAfwgPgQAodr169VLZsmXVrVs3rVu3TgcPHtTq1av1+OOP67fffpMkPfHEE3r11Ve1aNEi/fzzz3rkkUf+dg2/KlWqKC4uTv369dOiRYscfX788ceSpKioKNlsNi1evFjHjx9Xenq6/P399dRTT2nQoEGaOXOm9u/fr++//15vvvmmZs6cKUl6+OGHtXfvXj399NNKTk7W7NmzNWPGjOL+EQHAVUUCCKDYlSlTRmvXrlXlypUVGxurOnXqqH///srMzHRUBAcPHqz7779fcXFxio6Olr+/v26//fa/7Xfq1Km644479Mgjj6h27dp64IEHlJGRIUmqUKGCRowYoeeee07h4eF69NFHJUmjRo3S0KFDlZiYqDp16ujWW2/VF198oapVq0qSKleurAULFmjRokW6/vrrNW3aNL3yyivF+NMBgKvPZlxphjUAAABKJCqAAAAAFkMCCAAAYDEkgAAAABZDAggAAGAxJIAAAAAWQwIIAABgMSSAAAAAFkMCCAAAYDEkgAAAABZDAggAAGAxJIAAAAAW8/8AnijEHWDBybEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.1328\n",
            "Test accuracy: 65.18\n",
            "Train loss: 0.3988\n",
            "Train accuracy: 84.24\n",
            "Recall: 0.65\n",
            "Precision: 0.63\n",
            "F1-score: 0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16  # Import VGG16 architecture\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Define your data directories\n",
        "train_dir = '/content/drive/MyDrive/new datasets severe/train'\n",
        "val_dir = '/content/drive/MyDrive/new datasets severe/validation'\n",
        "test_dir = '/content/drive/MyDrive/new datasets severe/test'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # Load VGG16\n",
        "\n",
        "# Flatten the output of VGG16\n",
        "x = Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer for classification\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=200,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.n // batch_size)\n",
        "train_loss, train_accuracy = model.evaluate(train_generator, steps=train_generator.n // batch_size)\n",
        "\n",
        "# Calculate recall\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i in range(test_generator.n // batch_size):\n",
        "    batch_x, batch_y = next(test_generator)\n",
        "    y_true.extend(np.argmax(batch_y, axis=1))\n",
        "    y_pred.extend(np.argmax(model.predict(batch_x), axis=1))\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Minor', ' Moderate', 'Severe'], yticklabels=['Minor', ' Moderate', 'Severe'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Calculate other metrics\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Display metrics\n",
        "print(f'Test loss: {test_loss:.4f}')\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}')\n",
        "print(f'Train loss: {train_loss:.4f}')\n",
        "print(f'Train accuracy: {train_accuracy * 100:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/colabtest/vecicle_damage_VGG16_epoch_60_severity_new_dataset.h5')\n"
      ]
    }
  ]
}