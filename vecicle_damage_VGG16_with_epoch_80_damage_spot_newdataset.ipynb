{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1XEDwwfTnD93WEBvYadyk_Mah6KqQQD1a",
      "authorship_tag": "ABX9TyOosJjspn5vdVuJeudrhR30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megha-puthukudi/main-project/blob/vgg16_spot/vecicle_damage_VGG16_with_epoch_80_damage_spot_newdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyhPMYKdArGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa956a03-0f76-4960-e650-7ce9f7f7e0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1050 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n",
            "Found 215 images belonging to 3 classes.\n",
            "Epoch 1/80\n",
            "65/65 [==============================] - 23s 338ms/step - loss: 2.8730 - accuracy: 0.3878 - val_loss: 2.7272 - val_accuracy: 0.4375\n",
            "Epoch 2/80\n",
            "65/65 [==============================] - 21s 325ms/step - loss: 2.5899 - accuracy: 0.4120 - val_loss: 2.4903 - val_accuracy: 0.4777\n",
            "Epoch 3/80\n",
            "65/65 [==============================] - 21s 325ms/step - loss: 2.3630 - accuracy: 0.4410 - val_loss: 2.1935 - val_accuracy: 0.4955\n",
            "Epoch 4/80\n",
            "65/65 [==============================] - 21s 330ms/step - loss: 2.2324 - accuracy: 0.4526 - val_loss: 2.1078 - val_accuracy: 0.5223\n",
            "Epoch 5/80\n",
            "65/65 [==============================] - 19s 299ms/step - loss: 2.1199 - accuracy: 0.4710 - val_loss: 1.9084 - val_accuracy: 0.5402\n",
            "Epoch 6/80\n",
            "65/65 [==============================] - 21s 318ms/step - loss: 1.8928 - accuracy: 0.4961 - val_loss: 1.7997 - val_accuracy: 0.5446\n",
            "Epoch 7/80\n",
            "65/65 [==============================] - 19s 299ms/step - loss: 1.7794 - accuracy: 0.5116 - val_loss: 1.7778 - val_accuracy: 0.5536\n",
            "Epoch 8/80\n",
            "65/65 [==============================] - 21s 323ms/step - loss: 1.7393 - accuracy: 0.5019 - val_loss: 1.6644 - val_accuracy: 0.5848\n",
            "Epoch 9/80\n",
            "65/65 [==============================] - 21s 319ms/step - loss: 1.6321 - accuracy: 0.5290 - val_loss: 1.5742 - val_accuracy: 0.5848\n",
            "Epoch 10/80\n",
            "65/65 [==============================] - 20s 305ms/step - loss: 1.6231 - accuracy: 0.5358 - val_loss: 1.5184 - val_accuracy: 0.5848\n",
            "Epoch 11/80\n",
            "65/65 [==============================] - 21s 319ms/step - loss: 1.5485 - accuracy: 0.5532 - val_loss: 1.4840 - val_accuracy: 0.5982\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix\n",
        "import seaborn as sns  # Added seaborn for visualization\n",
        "\n",
        "# Define your data directories\n",
        "train_dir = '/content/drive/MyDrive/dataset for spot/train'\n",
        "val_dir = '/content/drive/MyDrive/dataset for spot/validation'\n",
        "test_dir = '/content/drive/MyDrive/dataset for spot/test'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add a global average pooling layer\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "\n",
        "\n",
        "# Add a dense output layer with softmax activation\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=80,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.n // batch_size)\n",
        "train_loss, train_accuracy = model.evaluate(train_generator, steps=train_generator.n // batch_size)\n",
        "\n",
        "# Calculate recall\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i in range(test_generator.n // batch_size):\n",
        "    batch_x, batch_y = next(test_generator)\n",
        "    y_true.extend(np.argmax(batch_y, axis=1))\n",
        "    y_pred.extend(np.argmax(model.predict(batch_x), axis=1))\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(5, 3))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['front', 'rear', 'side'], yticklabels=['front', 'rear', 'side'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Calculate other metrics\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "# Display metrics\n",
        "print(f'Test loss: {test_loss:.4f}')\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}')\n",
        "print(f'Train loss: {train_loss:.4f}')\n",
        "print(f'Train accuracy: {train_accuracy * 100:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/colabtest/vecicle_spot_position_VGG16_epoch_80_dataset.h5')\n"
      ]
    }
  ]
}