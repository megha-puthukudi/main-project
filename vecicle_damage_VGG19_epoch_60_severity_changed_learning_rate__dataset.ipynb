{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rpyupEsFJQfwYpi1aWwdCYdam1flkpAC",
      "authorship_tag": "ABX9TyMFnJqncuqOc+9Olp8nqYyV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megha-puthukudi/main-project/blob/VGG19_SEVERE/vecicle_damage_VGG19_epoch_60_severity_changed_learning_rate__dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ORF-oY8tHdfR",
        "outputId": "39a2ca92-5577-41be-f0f0-f302f1c1921b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 295 images belonging to 3 classes.\n",
            "Found 60 images belonging to 3 classes.\n",
            "Found 60 images belonging to 3 classes.\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 24s 1s/step - loss: 1.1453 - accuracy: 0.3047 - val_loss: 1.1517 - val_accuracy: 0.3333\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 5s 269ms/step - loss: 1.1154 - accuracy: 0.3763 - val_loss: 1.1351 - val_accuracy: 0.3125\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 6s 342ms/step - loss: 1.1284 - accuracy: 0.3264 - val_loss: 1.1188 - val_accuracy: 0.3542\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 5s 273ms/step - loss: 1.1054 - accuracy: 0.3763 - val_loss: 1.1083 - val_accuracy: 0.4167\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 5s 274ms/step - loss: 1.0998 - accuracy: 0.4086 - val_loss: 1.0758 - val_accuracy: 0.3750\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 6s 332ms/step - loss: 1.0607 - accuracy: 0.4337 - val_loss: 1.0647 - val_accuracy: 0.3542\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 5s 268ms/step - loss: 1.0403 - accuracy: 0.4479 - val_loss: 1.0305 - val_accuracy: 0.4583\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 6s 343ms/step - loss: 1.0662 - accuracy: 0.4373 - val_loss: 1.0647 - val_accuracy: 0.3958\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 5s 275ms/step - loss: 1.0339 - accuracy: 0.4875 - val_loss: 1.0463 - val_accuracy: 0.4167\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 6s 353ms/step - loss: 1.0518 - accuracy: 0.4306 - val_loss: 1.0295 - val_accuracy: 0.4583\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 5s 296ms/step - loss: 1.0211 - accuracy: 0.4910 - val_loss: 1.0344 - val_accuracy: 0.4167\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 6s 320ms/step - loss: 0.9986 - accuracy: 0.4839 - val_loss: 0.9980 - val_accuracy: 0.6042\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 6s 349ms/step - loss: 0.9958 - accuracy: 0.5347 - val_loss: 0.9693 - val_accuracy: 0.5833\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 5s 276ms/step - loss: 1.0052 - accuracy: 0.5054 - val_loss: 1.0146 - val_accuracy: 0.5208\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 5s 295ms/step - loss: 0.9968 - accuracy: 0.4803 - val_loss: 0.9772 - val_accuracy: 0.5208\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 5s 275ms/step - loss: 0.9705 - accuracy: 0.5233 - val_loss: 0.9584 - val_accuracy: 0.5833\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 6s 343ms/step - loss: 0.9705 - accuracy: 0.5735 - val_loss: 0.9645 - val_accuracy: 0.5625\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 5s 281ms/step - loss: 0.9581 - accuracy: 0.5556 - val_loss: 0.9281 - val_accuracy: 0.6042\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 5s 288ms/step - loss: 0.9382 - accuracy: 0.5950 - val_loss: 0.9466 - val_accuracy: 0.6042\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 5s 289ms/step - loss: 0.9492 - accuracy: 0.5735 - val_loss: 0.9887 - val_accuracy: 0.5208\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 6s 343ms/step - loss: 0.9451 - accuracy: 0.5556 - val_loss: 0.9982 - val_accuracy: 0.5208\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 5s 297ms/step - loss: 0.9401 - accuracy: 0.5341 - val_loss: 0.9322 - val_accuracy: 0.5625\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 6s 327ms/step - loss: 0.9205 - accuracy: 0.5806 - val_loss: 0.9264 - val_accuracy: 0.6042\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 5s 271ms/step - loss: 0.9245 - accuracy: 0.6057 - val_loss: 0.9380 - val_accuracy: 0.5625\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 6s 358ms/step - loss: 0.9452 - accuracy: 0.5520 - val_loss: 0.9289 - val_accuracy: 0.5833\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 5s 285ms/step - loss: 0.9075 - accuracy: 0.5878 - val_loss: 0.9101 - val_accuracy: 0.6042\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 6s 352ms/step - loss: 0.9431 - accuracy: 0.5412 - val_loss: 0.8841 - val_accuracy: 0.6667\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 6s 308ms/step - loss: 0.9110 - accuracy: 0.6129 - val_loss: 0.9059 - val_accuracy: 0.6042\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 6s 307ms/step - loss: 0.9129 - accuracy: 0.6129 - val_loss: 0.9147 - val_accuracy: 0.6250\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 5s 283ms/step - loss: 0.8933 - accuracy: 0.5950 - val_loss: 0.8809 - val_accuracy: 0.6042\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 5s 290ms/step - loss: 0.9166 - accuracy: 0.5842 - val_loss: 0.8899 - val_accuracy: 0.5625\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 5s 266ms/step - loss: 0.8761 - accuracy: 0.6523 - val_loss: 0.8787 - val_accuracy: 0.6458\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 5s 263ms/step - loss: 0.8940 - accuracy: 0.5771 - val_loss: 0.8931 - val_accuracy: 0.6667\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 6s 337ms/step - loss: 0.8898 - accuracy: 0.6022 - val_loss: 0.8405 - val_accuracy: 0.7083\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 5s 297ms/step - loss: 0.9018 - accuracy: 0.5627 - val_loss: 0.8861 - val_accuracy: 0.6458\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 6s 302ms/step - loss: 0.8739 - accuracy: 0.5878 - val_loss: 0.8370 - val_accuracy: 0.6875\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 5s 275ms/step - loss: 0.8508 - accuracy: 0.6380 - val_loss: 0.8721 - val_accuracy: 0.6667\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 6s 338ms/step - loss: 0.8558 - accuracy: 0.6487 - val_loss: 0.9111 - val_accuracy: 0.5417\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 5s 271ms/step - loss: 0.8623 - accuracy: 0.6452 - val_loss: 0.8897 - val_accuracy: 0.6250\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 5s 295ms/step - loss: 0.8834 - accuracy: 0.5950 - val_loss: 0.8629 - val_accuracy: 0.7083\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 6s 332ms/step - loss: 0.8900 - accuracy: 0.6201 - val_loss: 0.8520 - val_accuracy: 0.6875\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 5s 282ms/step - loss: 0.8703 - accuracy: 0.6165 - val_loss: 0.8790 - val_accuracy: 0.6458\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 5s 282ms/step - loss: 0.8899 - accuracy: 0.6165 - val_loss: 0.9155 - val_accuracy: 0.5208\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 6s 315ms/step - loss: 0.8361 - accuracy: 0.6165 - val_loss: 0.8304 - val_accuracy: 0.7292\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 5s 288ms/step - loss: 0.8426 - accuracy: 0.6201 - val_loss: 0.8490 - val_accuracy: 0.6250\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 5s 285ms/step - loss: 0.8565 - accuracy: 0.5986 - val_loss: 0.8380 - val_accuracy: 0.6875\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 6s 338ms/step - loss: 0.8607 - accuracy: 0.6165 - val_loss: 0.8455 - val_accuracy: 0.6875\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 5s 293ms/step - loss: 0.8487 - accuracy: 0.6057 - val_loss: 0.8553 - val_accuracy: 0.6250\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 6s 301ms/step - loss: 0.8913 - accuracy: 0.5950 - val_loss: 0.8633 - val_accuracy: 0.6042\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 6s 328ms/step - loss: 0.8518 - accuracy: 0.5950 - val_loss: 0.8942 - val_accuracy: 0.6875\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 5s 262ms/step - loss: 0.8351 - accuracy: 0.6344 - val_loss: 0.8111 - val_accuracy: 0.7708\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 5s 276ms/step - loss: 0.8419 - accuracy: 0.6093 - val_loss: 0.8631 - val_accuracy: 0.7083\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 6s 316ms/step - loss: 0.8452 - accuracy: 0.6272 - val_loss: 0.8260 - val_accuracy: 0.7083\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 5s 271ms/step - loss: 0.8211 - accuracy: 0.6559 - val_loss: 0.8217 - val_accuracy: 0.6875\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 6s 350ms/step - loss: 0.8555 - accuracy: 0.6181 - val_loss: 0.8502 - val_accuracy: 0.6458\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 5s 265ms/step - loss: 0.8263 - accuracy: 0.6093 - val_loss: 0.8409 - val_accuracy: 0.6875\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 5s 264ms/step - loss: 0.8524 - accuracy: 0.6380 - val_loss: 0.8177 - val_accuracy: 0.7083\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 6s 339ms/step - loss: 0.8242 - accuracy: 0.6416 - val_loss: 0.8197 - val_accuracy: 0.7708\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 6s 321ms/step - loss: 0.8290 - accuracy: 0.6523 - val_loss: 0.8668 - val_accuracy: 0.6875\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 5s 267ms/step - loss: 0.8322 - accuracy: 0.6057 - val_loss: 0.8285 - val_accuracy: 0.7083\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 5s 260ms/step - loss: 0.8139 - accuracy: 0.6416 - val_loss: 0.8688 - val_accuracy: 0.6458\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 6s 323ms/step - loss: 0.8191 - accuracy: 0.6452 - val_loss: 0.8838 - val_accuracy: 0.5833\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 5s 304ms/step - loss: 0.8266 - accuracy: 0.6272 - val_loss: 0.8538 - val_accuracy: 0.6667\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 6s 303ms/step - loss: 0.8141 - accuracy: 0.6416 - val_loss: 0.8382 - val_accuracy: 0.6875\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 6s 337ms/step - loss: 0.8045 - accuracy: 0.6487 - val_loss: 0.7801 - val_accuracy: 0.7917\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 5s 267ms/step - loss: 0.8178 - accuracy: 0.6344 - val_loss: 0.8398 - val_accuracy: 0.7292\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 6s 317ms/step - loss: 0.8315 - accuracy: 0.6344 - val_loss: 0.8293 - val_accuracy: 0.7083\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 5s 257ms/step - loss: 0.8253 - accuracy: 0.6129 - val_loss: 0.8379 - val_accuracy: 0.7083\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 6s 329ms/step - loss: 0.7989 - accuracy: 0.6667 - val_loss: 0.8194 - val_accuracy: 0.7500\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.8440 - accuracy: 0.6344 - val_loss: 0.8398 - val_accuracy: 0.6875\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 5s 277ms/step - loss: 0.8132 - accuracy: 0.6774 - val_loss: 0.7945 - val_accuracy: 0.6875\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 6s 307ms/step - loss: 0.8020 - accuracy: 0.6918 - val_loss: 0.8178 - val_accuracy: 0.6250\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 5s 262ms/step - loss: 0.7977 - accuracy: 0.6452 - val_loss: 0.8033 - val_accuracy: 0.7083\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 6s 334ms/step - loss: 0.8309 - accuracy: 0.6201 - val_loss: 0.7872 - val_accuracy: 0.7292\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.8045 - accuracy: 0.6308 - val_loss: 0.8656 - val_accuracy: 0.6875\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 5s 271ms/step - loss: 0.8350 - accuracy: 0.6272 - val_loss: 0.8562 - val_accuracy: 0.5833\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 6s 336ms/step - loss: 0.8162 - accuracy: 0.6237 - val_loss: 0.8241 - val_accuracy: 0.6875\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 5s 275ms/step - loss: 0.8030 - accuracy: 0.6452 - val_loss: 0.8062 - val_accuracy: 0.6875\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 6s 340ms/step - loss: 0.7825 - accuracy: 0.6703 - val_loss: 0.8273 - val_accuracy: 0.7083\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 5s 260ms/step - loss: 0.7932 - accuracy: 0.6487 - val_loss: 0.8232 - val_accuracy: 0.6667\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 5s 272ms/step - loss: 0.8088 - accuracy: 0.6452 - val_loss: 0.8457 - val_accuracy: 0.6875\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 6s 313ms/step - loss: 0.7973 - accuracy: 0.6416 - val_loss: 0.8511 - val_accuracy: 0.6667\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 6s 328ms/step - loss: 0.7756 - accuracy: 0.6487 - val_loss: 0.7884 - val_accuracy: 0.7083\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 5s 281ms/step - loss: 0.7890 - accuracy: 0.6487 - val_loss: 0.8081 - val_accuracy: 0.7292\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 6s 345ms/step - loss: 0.7854 - accuracy: 0.6559 - val_loss: 0.6977 - val_accuracy: 0.7917\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.8055 - accuracy: 0.6380 - val_loss: 0.8203 - val_accuracy: 0.6875\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 6s 333ms/step - loss: 0.7841 - accuracy: 0.6875 - val_loss: 0.7753 - val_accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 5s 263ms/step - loss: 0.7840 - accuracy: 0.6738 - val_loss: 0.8213 - val_accuracy: 0.7083\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 6s 340ms/step - loss: 0.7882 - accuracy: 0.6523 - val_loss: 0.8354 - val_accuracy: 0.6458\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.7939 - accuracy: 0.6416 - val_loss: 0.7822 - val_accuracy: 0.7292\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 5s 305ms/step - loss: 0.7702 - accuracy: 0.6774 - val_loss: 0.7678 - val_accuracy: 0.7292\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 5s 283ms/step - loss: 0.8028 - accuracy: 0.6319 - val_loss: 0.8478 - val_accuracy: 0.6667\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 5s 265ms/step - loss: 0.7991 - accuracy: 0.6523 - val_loss: 0.7805 - val_accuracy: 0.7083\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 6s 329ms/step - loss: 0.8116 - accuracy: 0.6380 - val_loss: 0.7809 - val_accuracy: 0.7083\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.7650 - accuracy: 0.6703 - val_loss: 0.7435 - val_accuracy: 0.7292\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 5s 281ms/step - loss: 0.7628 - accuracy: 0.6667 - val_loss: 0.8071 - val_accuracy: 0.7292\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 6s 336ms/step - loss: 0.7915 - accuracy: 0.6308 - val_loss: 0.7358 - val_accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.7734 - accuracy: 0.6272 - val_loss: 0.8034 - val_accuracy: 0.7083\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 6s 344ms/step - loss: 0.7676 - accuracy: 0.6631 - val_loss: 0.8275 - val_accuracy: 0.6875\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 5s 271ms/step - loss: 0.7497 - accuracy: 0.6918 - val_loss: 0.7569 - val_accuracy: 0.7083\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 6s 333ms/step - loss: 0.7911 - accuracy: 0.6344 - val_loss: 0.7491 - val_accuracy: 0.7708\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 5s 260ms/step - loss: 0.7548 - accuracy: 0.6738 - val_loss: 0.7184 - val_accuracy: 0.7500\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 6s 324ms/step - loss: 0.7568 - accuracy: 0.6738 - val_loss: 0.8198 - val_accuracy: 0.6875\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 5s 261ms/step - loss: 0.7396 - accuracy: 0.7061 - val_loss: 0.8099 - val_accuracy: 0.6875\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 6s 336ms/step - loss: 0.7606 - accuracy: 0.6523 - val_loss: 0.8314 - val_accuracy: 0.6875\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 6s 308ms/step - loss: 0.7775 - accuracy: 0.6344 - val_loss: 0.8112 - val_accuracy: 0.6875\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 5s 279ms/step - loss: 0.7596 - accuracy: 0.6559 - val_loss: 0.7799 - val_accuracy: 0.7083\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 6s 341ms/step - loss: 0.7659 - accuracy: 0.6452 - val_loss: 0.7750 - val_accuracy: 0.6458\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 5s 258ms/step - loss: 0.7543 - accuracy: 0.6667 - val_loss: 0.7883 - val_accuracy: 0.6458\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 5s 296ms/step - loss: 0.7728 - accuracy: 0.6523 - val_loss: 0.7373 - val_accuracy: 0.7083\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.7741 - accuracy: 0.6738 - val_loss: 0.8033 - val_accuracy: 0.6875\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 6s 327ms/step - loss: 0.7505 - accuracy: 0.6918 - val_loss: 0.7669 - val_accuracy: 0.7292\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.7587 - accuracy: 0.6667 - val_loss: 0.7611 - val_accuracy: 0.6875\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 6s 310ms/step - loss: 0.7557 - accuracy: 0.6810 - val_loss: 0.7900 - val_accuracy: 0.6875\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 5s 289ms/step - loss: 0.7769 - accuracy: 0.6667 - val_loss: 0.7622 - val_accuracy: 0.7292\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 5s 267ms/step - loss: 0.7002 - accuracy: 0.7384 - val_loss: 0.7895 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 6s 329ms/step - loss: 0.7960 - accuracy: 0.6487 - val_loss: 0.7728 - val_accuracy: 0.6667\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 5s 292ms/step - loss: 0.7339 - accuracy: 0.7133 - val_loss: 0.7319 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 6s 305ms/step - loss: 0.7063 - accuracy: 0.7419 - val_loss: 0.7427 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 6s 346ms/step - loss: 0.7342 - accuracy: 0.7025 - val_loss: 0.8007 - val_accuracy: 0.6458\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 5s 261ms/step - loss: 0.7508 - accuracy: 0.6595 - val_loss: 0.8062 - val_accuracy: 0.6250\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 6s 311ms/step - loss: 0.7635 - accuracy: 0.6918 - val_loss: 0.8084 - val_accuracy: 0.6250\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 5s 279ms/step - loss: 0.7228 - accuracy: 0.7049 - val_loss: 0.8185 - val_accuracy: 0.6875\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 6s 330ms/step - loss: 0.7500 - accuracy: 0.6989 - val_loss: 0.7993 - val_accuracy: 0.7083\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 5s 283ms/step - loss: 0.7473 - accuracy: 0.6631 - val_loss: 0.7813 - val_accuracy: 0.6875\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 5s 258ms/step - loss: 0.7415 - accuracy: 0.6882 - val_loss: 0.7518 - val_accuracy: 0.6875\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 6s 328ms/step - loss: 0.7232 - accuracy: 0.7133 - val_loss: 0.7771 - val_accuracy: 0.7083\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 0.7239 - accuracy: 0.7204 - val_loss: 0.8186 - val_accuracy: 0.7083\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 6s 317ms/step - loss: 0.7201 - accuracy: 0.6703 - val_loss: 0.8085 - val_accuracy: 0.6250\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 5s 256ms/step - loss: 0.7228 - accuracy: 0.7168 - val_loss: 0.7564 - val_accuracy: 0.6458\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 6s 317ms/step - loss: 0.7168 - accuracy: 0.7061 - val_loss: 0.7456 - val_accuracy: 0.7083\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.7459 - accuracy: 0.6846 - val_loss: 0.8099 - val_accuracy: 0.6667\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 5s 262ms/step - loss: 0.7381 - accuracy: 0.6882 - val_loss: 0.7189 - val_accuracy: 0.7292\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 6s 330ms/step - loss: 0.7457 - accuracy: 0.6774 - val_loss: 0.7975 - val_accuracy: 0.6667\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 5s 282ms/step - loss: 0.7331 - accuracy: 0.6703 - val_loss: 0.7836 - val_accuracy: 0.6250\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 6s 322ms/step - loss: 0.7470 - accuracy: 0.6523 - val_loss: 0.7325 - val_accuracy: 0.7083\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 5s 282ms/step - loss: 0.7155 - accuracy: 0.6810 - val_loss: 0.7750 - val_accuracy: 0.6667\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 6s 341ms/step - loss: 0.6940 - accuracy: 0.7097 - val_loss: 0.7767 - val_accuracy: 0.6875\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 5s 265ms/step - loss: 0.7336 - accuracy: 0.6882 - val_loss: 0.7929 - val_accuracy: 0.6667\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 6s 324ms/step - loss: 0.7410 - accuracy: 0.7061 - val_loss: 0.8094 - val_accuracy: 0.6667\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 5s 262ms/step - loss: 0.7151 - accuracy: 0.6846 - val_loss: 0.7489 - val_accuracy: 0.7500\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 5s 265ms/step - loss: 0.7257 - accuracy: 0.6989 - val_loss: 0.7908 - val_accuracy: 0.6667\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 6s 314ms/step - loss: 0.7237 - accuracy: 0.7097 - val_loss: 0.7374 - val_accuracy: 0.7083\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 6s 315ms/step - loss: 0.7234 - accuracy: 0.7204 - val_loss: 0.7638 - val_accuracy: 0.7083\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 5s 285ms/step - loss: 0.7411 - accuracy: 0.6703 - val_loss: 0.8072 - val_accuracy: 0.6667\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 6s 329ms/step - loss: 0.7423 - accuracy: 0.6810 - val_loss: 0.6808 - val_accuracy: 0.7292\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 5s 281ms/step - loss: 0.7100 - accuracy: 0.7061 - val_loss: 0.7210 - val_accuracy: 0.7083\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 6s 320ms/step - loss: 0.7097 - accuracy: 0.7061 - val_loss: 0.8035 - val_accuracy: 0.6458\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.7400 - accuracy: 0.6631 - val_loss: 0.7483 - val_accuracy: 0.6875\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 6s 337ms/step - loss: 0.7226 - accuracy: 0.6840 - val_loss: 0.7968 - val_accuracy: 0.6250\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 6s 310ms/step - loss: 0.7138 - accuracy: 0.6989 - val_loss: 0.7958 - val_accuracy: 0.6875\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 5s 273ms/step - loss: 0.7242 - accuracy: 0.6771 - val_loss: 0.7884 - val_accuracy: 0.6667\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 6s 352ms/step - loss: 0.7375 - accuracy: 0.6810 - val_loss: 0.7641 - val_accuracy: 0.7292\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 5s 291ms/step - loss: 0.7176 - accuracy: 0.7025 - val_loss: 0.7489 - val_accuracy: 0.6875\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 6s 308ms/step - loss: 0.7226 - accuracy: 0.6810 - val_loss: 0.7993 - val_accuracy: 0.6458\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 6s 301ms/step - loss: 0.7218 - accuracy: 0.6979 - val_loss: 0.7643 - val_accuracy: 0.6250\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 6s 333ms/step - loss: 0.7170 - accuracy: 0.7240 - val_loss: 0.8267 - val_accuracy: 0.6458\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 5s 285ms/step - loss: 0.7201 - accuracy: 0.7133 - val_loss: 0.7435 - val_accuracy: 0.7083\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 5s 276ms/step - loss: 0.7146 - accuracy: 0.6989 - val_loss: 0.8148 - val_accuracy: 0.6667\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.7187 - accuracy: 0.6774 - val_loss: 0.7869 - val_accuracy: 0.6458\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 6s 321ms/step - loss: 0.7026 - accuracy: 0.7133 - val_loss: 0.7117 - val_accuracy: 0.7083\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 5s 284ms/step - loss: 0.7139 - accuracy: 0.6875 - val_loss: 0.7734 - val_accuracy: 0.6875\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 5s 291ms/step - loss: 0.7444 - accuracy: 0.6882 - val_loss: 0.7297 - val_accuracy: 0.7083\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 5s 266ms/step - loss: 0.7025 - accuracy: 0.6989 - val_loss: 0.7479 - val_accuracy: 0.6875\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 5s 284ms/step - loss: 0.6969 - accuracy: 0.7204 - val_loss: 0.7831 - val_accuracy: 0.6875\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 5s 282ms/step - loss: 0.7253 - accuracy: 0.6910 - val_loss: 0.7169 - val_accuracy: 0.7083\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 6s 331ms/step - loss: 0.7164 - accuracy: 0.7025 - val_loss: 0.7799 - val_accuracy: 0.6667\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 5s 284ms/step - loss: 0.6914 - accuracy: 0.6953 - val_loss: 0.7250 - val_accuracy: 0.6875\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 5s 284ms/step - loss: 0.7355 - accuracy: 0.6882 - val_loss: 0.7433 - val_accuracy: 0.6667\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 5s 285ms/step - loss: 0.7112 - accuracy: 0.6989 - val_loss: 0.8047 - val_accuracy: 0.6458\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 6s 320ms/step - loss: 0.7124 - accuracy: 0.6810 - val_loss: 0.7614 - val_accuracy: 0.6667\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 5s 294ms/step - loss: 0.7076 - accuracy: 0.7188 - val_loss: 0.7228 - val_accuracy: 0.7083\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 6s 320ms/step - loss: 0.7160 - accuracy: 0.7276 - val_loss: 0.8048 - val_accuracy: 0.6250\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 5s 272ms/step - loss: 0.6796 - accuracy: 0.7348 - val_loss: 0.7861 - val_accuracy: 0.6458\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 6s 331ms/step - loss: 0.6863 - accuracy: 0.7168 - val_loss: 0.7777 - val_accuracy: 0.6875\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.7255 - accuracy: 0.6989 - val_loss: 0.7116 - val_accuracy: 0.6875\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 5s 268ms/step - loss: 0.6986 - accuracy: 0.7025 - val_loss: 0.7349 - val_accuracy: 0.6458\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 6s 327ms/step - loss: 0.7189 - accuracy: 0.6810 - val_loss: 0.7822 - val_accuracy: 0.6250\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 5s 291ms/step - loss: 0.7002 - accuracy: 0.7061 - val_loss: 0.8228 - val_accuracy: 0.6250\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 6s 357ms/step - loss: 0.6898 - accuracy: 0.7204 - val_loss: 0.7963 - val_accuracy: 0.6667\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 5s 285ms/step - loss: 0.6930 - accuracy: 0.6953 - val_loss: 0.7896 - val_accuracy: 0.6667\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 6s 295ms/step - loss: 0.6998 - accuracy: 0.7061 - val_loss: 0.8229 - val_accuracy: 0.6250\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 5s 297ms/step - loss: 0.7153 - accuracy: 0.6703 - val_loss: 0.8039 - val_accuracy: 0.6042\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 5s 267ms/step - loss: 0.7101 - accuracy: 0.6846 - val_loss: 0.7368 - val_accuracy: 0.7083\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 6s 333ms/step - loss: 0.6736 - accuracy: 0.6882 - val_loss: 0.7967 - val_accuracy: 0.6250\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 5s 286ms/step - loss: 0.6879 - accuracy: 0.7168 - val_loss: 0.7500 - val_accuracy: 0.6667\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 6s 316ms/step - loss: 0.6776 - accuracy: 0.7133 - val_loss: 0.7864 - val_accuracy: 0.6667\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 5s 286ms/step - loss: 0.6910 - accuracy: 0.7168 - val_loss: 0.8045 - val_accuracy: 0.6250\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 6s 346ms/step - loss: 0.6914 - accuracy: 0.6882 - val_loss: 0.7996 - val_accuracy: 0.6042\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 5s 278ms/step - loss: 0.7043 - accuracy: 0.6774 - val_loss: 0.7443 - val_accuracy: 0.6458\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 6s 334ms/step - loss: 0.6875 - accuracy: 0.7025 - val_loss: 0.7442 - val_accuracy: 0.6667\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 5s 287ms/step - loss: 0.6979 - accuracy: 0.6846 - val_loss: 0.7479 - val_accuracy: 0.6458\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 6s 307ms/step - loss: 0.6643 - accuracy: 0.7204 - val_loss: 0.8003 - val_accuracy: 0.6250\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 5s 284ms/step - loss: 0.7026 - accuracy: 0.7025 - val_loss: 0.7635 - val_accuracy: 0.6458\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 6s 344ms/step - loss: 0.7216 - accuracy: 0.6989 - val_loss: 0.7196 - val_accuracy: 0.7083\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 5s 266ms/step - loss: 0.6847 - accuracy: 0.7133 - val_loss: 0.7669 - val_accuracy: 0.6250\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 5s 302ms/step - loss: 0.6562 - accuracy: 0.7276 - val_loss: 0.7974 - val_accuracy: 0.6250\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 0.6883 - accuracy: 0.7097 - val_loss: 0.7687 - val_accuracy: 0.6667\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 6s 325ms/step - loss: 0.6620 - accuracy: 0.7670 - val_loss: 0.7850 - val_accuracy: 0.6042\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 5s 283ms/step - loss: 0.6621 - accuracy: 0.7312 - val_loss: 0.8172 - val_accuracy: 0.6042\n",
            "3/3 [==============================] - 11s 5s/step - loss: 0.6457 - accuracy: 0.6875\n",
            "18/18 [==============================] - 5s 257ms/step - loss: 0.6772 - accuracy: 0.7153\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6457\n",
            "Test accuracy: 68.75\n",
            "Train loss: 0.6772\n",
            "Train accuracy: 71.53\n",
            "Recall: 0.61\n",
            "Precision: 0.57\n",
            "F1-score: 0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19  # Import VGG19 architecture\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Define your data directories\n",
        "train_dir = '/content/drive/MyDrive/dataset sevire/train'\n",
        "val_dir = '/content/drive/MyDrive/dataset sevire/validation'\n",
        "test_dir = '/content/drive/MyDrive/dataset sevire/test'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG19 model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # Load VGG19\n",
        "\n",
        "# Flatten the output of VGG19\n",
        "x = Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer for classification\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=200,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.n // batch_size)\n",
        "train_loss, train_accuracy = model.evaluate(train_generator, steps=train_generator.n // batch_size)\n",
        "\n",
        "# Calculate recall\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i in range(test_generator.n // batch_size):\n",
        "    batch_x, batch_y = next(test_generator)\n",
        "    y_true.extend(np.argmax(batch_y, axis=1))\n",
        "    y_pred.extend(np.argmax(model.predict(batch_x), axis=1))\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Minor', ' Moderate', 'Severe'], yticklabels=['Minor', ' Moderate', 'Severe'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Calculate other metrics\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Display metrics\n",
        "print(f'Test loss: {test_loss:.4f}')\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}')\n",
        "print(f'Train loss: {train_loss:.4f}')\n",
        "print(f'Train accuracy: {train_accuracy * 100:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/colabtest/vecicle_damage_VGG19_epoch_60_severity_changed_learning_rate_dataset.h5')\n"
      ]
    }
  ]
}